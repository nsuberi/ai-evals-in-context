{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Evaluation Workshop: Building Trust in Automated Judgment\n",
    "\n",
    "This notebook teaches you to build, validate, and monitor AI evaluation pipelines using a mortgage lending assistant as our running example. By the end, you'll have a framework for answering the question every stakeholder asks: **\"How do we know the AI is doing a good job?\"**\n",
    "\n",
    "**Key insight:** Governance is an accelerator, not a gate. Confidence in automated evaluation comes from systematically comparing machine judgment against human judgment.\n",
    "\n",
    "| Section | Topic | What You'll Build |\n",
    "|---------|-------|-------------------|\n",
    "| 1 | Assertions & Basic deepeval | RAG pipeline + generic quality metrics |\n",
    "| 2 | Custom Metrics | Domain-specific GEval metrics for compliance & actionability |\n",
    "| 3 | Golden Dataset | Acceptance criteria with positive and negative examples |\n",
    "| 4 | Inter-Rater Reliability | Cohen's kappa — does the machine agree with the human? |\n",
    "| 5 | Multiple Evaluators | Pairwise and Fleiss' kappa across a team |\n",
    "| 6 | Production Monitoring | Diagnose metric failures, refine the system prompt, re-evaluate |\n",
    "| 7 | Improving the LLM-as-Judge | Diagnose judge bias, refine evaluation steps, re-measure kappa |\n",
    "\n",
    "**Requirements:** Python 3.12+, Anthropic API key in `.env`, packages from `requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:12:08.005492Z",
     "iopub.status.busy": "2026-02-20T12:12:08.004732Z",
     "iopub.status.idle": "2026-02-20T12:12:08.034328Z",
     "shell.execute_reply": "2026-02-20T12:12:08.031349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: sk-ant-api03...yQAA\n",
      "Environment ready.\n",
      "LangSmith tracing enabled (project: ai-eval-workshop)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import warnings\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Opt out of deepeval telemetry before any deepeval imports\n",
    "os.environ[\"DEEPEVAL_TELEMETRY_OPT_IN\"] = \"NO\"\n",
    "\n",
    "# Suppress asyncio noise from deepeval's internal async operations:\n",
    "#  - \"Task was destroyed but it is pending!\" warnings\n",
    "#  - \"coroutine was never awaited\" RuntimeWarnings\n",
    "#  - \"Exception in callback Task.__step()\" / \"cannot enter context\" errors\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"coroutine.*was never awaited\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Task was destroyed.*\")\n",
    "logging.getLogger(\"asyncio\").setLevel(logging.CRITICAL)\n",
    "\n",
    "# Monkey-patch asyncio.new_event_loop so that every event loop deepeval\n",
    "# creates internally has a silent exception handler (suppresses noisy\n",
    "# \"Exception in callback\" tracebacks that clutter notebook output).\n",
    "#\n",
    "# Why the guard?  In a notebook, users often re-run this cell.  Without\n",
    "# the guard, the second run would capture the *already-patched* function\n",
    "# as _orig, so _quiet_new_event_loop would call itself → infinite\n",
    "# recursion.  Storing the original on the asyncio module and checking\n",
    "# for it ensures we only patch once per kernel session.\n",
    "if not hasattr(asyncio, '_orig_new_event_loop'):\n",
    "    asyncio._orig_new_event_loop = asyncio.new_event_loop\n",
    "\n",
    "    def _quiet_new_event_loop():\n",
    "        loop = asyncio._orig_new_event_loop()\n",
    "        loop.set_exception_handler(lambda _loop, _ctx: None)\n",
    "        return loop\n",
    "\n",
    "    asyncio.new_event_loop = _quiet_new_event_loop\n",
    "\n",
    "# Also silence the main thread's existing event loop\n",
    "try:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.set_exception_handler(lambda _loop, _ctx: None)\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "if not api_key:\n",
    "    raise EnvironmentError(\n",
    "        \"ANTHROPIC_API_KEY not found. \"\n",
    "        \"Create a .env file in this directory with: ANTHROPIC_API_KEY=sk-ant-...\"\n",
    "    )\n",
    "\n",
    "print(f\"API key loaded: {api_key[:12]}...{api_key[-4:]}\")\n",
    "print(\"Environment ready.\")\n",
    "\n",
    "# Configure LangSmith tracing (uses LANGSMITH_API_KEY from .env)\n",
    "langsmith_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "if langsmith_key:\n",
    "    os.environ.setdefault(\"LANGCHAIN_TRACING_V2\", \"true\")\n",
    "    os.environ.setdefault(\"LANGCHAIN_API_KEY\", langsmith_key)\n",
    "    project = os.getenv(\"LANGCHAIN_PROJECT\", \"default\")\n",
    "    print(f\"LangSmith tracing enabled (project: {project})\")\n",
    "else:\n",
    "    print(\"LangSmith API key not found — tracing disabled. Add LANGSMITH_API_KEY to .env for observability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Assertions and Basic deepeval\n",
    "\n",
    "If you've written unit tests, you already understand AI evaluation. The concepts map directly:\n",
    "\n",
    "| Classical Testing | AI Evaluation |\n",
    "|-------------------|---------------|\n",
    "| Unit test | Single test case (input + expected output) |\n",
    "| Assertion | Metric pass/fail (e.g., is the response faithful?) |\n",
    "| Test suite | Evaluation dataset |\n",
    "| Regression test | Golden dataset comparison |\n",
    "| Code coverage | Metric coverage across quality dimensions |\n",
    "\n",
    "The difference: instead of checking exact equality (`assertEqual`), we use **LLM-as-judge** metrics that produce **binary pass/fail verdicts**. The judge reads the question, context, and answer, then decides: does this meet the bar, or not? Let's build a system to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:12:08.150169Z",
     "iopub.status.busy": "2026-02-20T12:12:08.149600Z",
     "iopub.status.idle": "2026-02-20T12:12:08.171329Z",
     "shell.execute_reply": "2026-02-20T12:12:08.168626Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define our mortgage knowledge base as plain strings.\n",
    "# In production, these would come from your document management system.\n",
    "\n",
    "MORTGAGE_DOCS = {\n",
    "    \"loan_types\": \"\"\"MORTGAGE LOAN TYPES AND ELIGIBILITY\n",
    "\n",
    "Conventional Loans: Available for borrowers with credit scores of 620 or higher.\n",
    "Down payment requirements start at 3% for first-time buyers and 5% for repeat\n",
    "buyers. Private mortgage insurance (PMI) is required when down payment is less\n",
    "than 20%. PMI can be removed once the loan-to-value ratio reaches 78%. Maximum\n",
    "debt-to-income ratio is 45% for most programs, though exceptions exist for\n",
    "borrowers with strong compensating factors such as significant cash reserves.\n",
    "\n",
    "FHA Loans: Insured by the Federal Housing Administration. Minimum credit score\n",
    "of 580 for 3.5% down payment, or 500-579 with 10% down. More flexible\n",
    "qualification guidelines than conventional loans. Mortgage insurance premium\n",
    "(MIP) is required for the life of the loan regardless of equity. Maximum\n",
    "loan amounts vary by county — check HUD's lookup tool for your area.\n",
    "\n",
    "VA Loans: Available to eligible veterans, active-duty service members, and\n",
    "surviving spouses. No down payment required. No private mortgage insurance.\n",
    "Funding fee applies (ranges from 1.25% to 3.3% depending on service history\n",
    "and down payment). Competitive interest rates due to government backing.\n",
    "\n",
    "Jumbo Loans: For loan amounts exceeding conforming limits ($766,550 in most\n",
    "areas for 2024, higher in designated high-cost areas). Typically require\n",
    "credit scores of 700+, down payments of 10-20%, and more extensive income\n",
    "documentation. Interest rates may be slightly higher than conforming loans.\"\"\",\n",
    "\n",
    "    \"rate_locks\": \"\"\"RATE LOCK POLICIES AND PROCEDURES\n",
    "\n",
    "A rate lock guarantees a specific interest rate for a defined period while your\n",
    "loan application is processed. Rate locks protect borrowers from market\n",
    "fluctuations during the processing period.\n",
    "\n",
    "Standard Lock Periods: 30-day locks are included at no additional cost. 45-day\n",
    "locks carry a 0.125% fee. 60-day locks carry a 0.250% fee. Extended locks\n",
    "beyond 60 days are available on a case-by-case basis and may carry higher fees.\n",
    "\n",
    "Lock Timing: Locks can be placed at application, at approval, or at any point\n",
    "during processing. Once locked, the rate is guaranteed even if market rates\n",
    "rise. If market rates fall after locking, a one-time float-down option may be\n",
    "available for a 0.125% fee, subject to a minimum rate improvement of 0.25%.\n",
    "\n",
    "Lock Expiration: If the lock expires before closing, the borrower may need to\n",
    "re-lock at current market rates, which could be higher. Extension fees apply:\n",
    "typically 0.125% per 7-day extension. To avoid expiration, ensure all\n",
    "documentation is submitted promptly and respond to underwriting conditions\n",
    "within 48 hours.\n",
    "\n",
    "Important: Rate quotes provided during initial consultation are estimates only\n",
    "and do not constitute a rate lock. Rates are not guaranteed until a formal\n",
    "lock confirmation is issued in writing.\"\"\",\n",
    "\n",
    "    \"escrow_closing\": \"\"\"ESCROW AND CLOSING PROCEDURES\n",
    "\n",
    "Escrow Account: An escrow account holds funds for property taxes and homeowner's\n",
    "insurance. Monthly payments include principal, interest, taxes, and insurance\n",
    "(PITI). The initial escrow deposit at closing typically covers 2-3 months of\n",
    "taxes and insurance as a cushion.\n",
    "\n",
    "Closing Disclosure: Federal law requires borrowers receive a Closing Disclosure\n",
    "at least 3 business days before closing. This document details final loan\n",
    "terms, monthly payments, closing costs, and cash required at closing. Review\n",
    "it carefully and compare with your original Loan Estimate.\n",
    "\n",
    "Closing Costs: Typically range from 2% to 5% of the loan amount. Include:\n",
    "origination fees, appraisal fee ($400-700), title search and insurance,\n",
    "recording fees, prepaid interest, and initial escrow deposits. Some costs\n",
    "are negotiable — ask your loan officer about lender credits or seller\n",
    "concessions.\n",
    "\n",
    "Required at Closing: Government-issued photo ID, certified or cashier's check\n",
    "for closing costs (personal checks not accepted for amounts over $1,000),\n",
    "proof of homeowner's insurance, and any outstanding documentation requested\n",
    "by underwriting.\n",
    "\n",
    "Post-Closing: Loan servicing may be transferred to a different servicer within\n",
    "60 days of closing. You will receive written notice of any transfer. Your\n",
    "loan terms cannot change due to a servicing transfer.\"\"\",\n",
    "\n",
    "    \"underwriting_compliance\": \"\"\"UNDERWRITING GUIDELINES AND COMPLIANCE\n",
    "\n",
    "Income Verification: All income must be documented with at least 2 years of\n",
    "tax returns, recent pay stubs (30 days), and W-2s or 1099s. Self-employed\n",
    "borrowers require 2 years of business tax returns and a year-to-date profit\n",
    "and loss statement. Verbal verification of employment is conducted within\n",
    "10 business days of closing.\n",
    "\n",
    "Asset Documentation: Bank statements for the most recent 2 months for all\n",
    "accounts used for down payment and closing costs. Large deposits (generally\n",
    "over 50% of monthly income) must be sourced with documentation. Gift funds\n",
    "are permitted from family members with a signed gift letter confirming no\n",
    "repayment is expected.\n",
    "\n",
    "Appraisal Requirements: An independent appraisal is required for all purchase\n",
    "transactions and most refinances. The property must meet minimum condition\n",
    "standards. If the appraisal comes in below the purchase price, options\n",
    "include: renegotiating the price, increasing down payment, requesting a\n",
    "reconsideration of value, or canceling the transaction per contract terms.\n",
    "\n",
    "Compliance Notes: All lending decisions comply with the Equal Credit\n",
    "Opportunity Act (ECOA), Fair Housing Act, and Truth in Lending Act (TILA).\n",
    "Borrowers have the right to receive a copy of the appraisal report at no\n",
    "additional charge. Adverse action notices are provided within 30 days when\n",
    "an application is denied, explaining the specific reasons for the decision.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:12:08.185570Z",
     "iopub.status.busy": "2026-02-20T12:12:08.184939Z",
     "iopub.status.idle": "2026-02-20T12:12:13.452033Z",
     "shell.execute_reply": "2026-02-20T12:12:13.449369Z"
    }
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Use an ephemeral (in-memory) client — no disk artifacts\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "\n",
    "# get_or_create so re-running this cell doesn't fail\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"mortgage_knowledge_base\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "# Upsert so re-runs update rather than duplicate\n",
    "collection.upsert(\n",
    "    documents=list(MORTGAGE_DOCS.values()),\n",
    "    ids=list(MORTGAGE_DOCS.keys())\n",
    ")\n",
    "\n",
    "print(f\"Loaded {collection.count()} documents into ChromaDB\")\n",
    "for doc_id in MORTGAGE_DOCS:\n",
    "    print(f\"  - {doc_id} ({len(MORTGAGE_DOCS[doc_id])} chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RAG Pipeline\n",
    "\n",
    "Our mortgage assistant uses a standard **Retrieval-Augmented Generation** (RAG) pattern:\n",
    "\n",
    "1. **Retrieve**: Query ChromaDB for the most relevant document(s)\n",
    "2. **Augment**: Include retrieved context in the prompt\n",
    "3. **Generate**: Claude produces an answer grounded in the context\n",
    "\n",
    "This is the system we'll be evaluating — not the model itself, but the **complete pipeline** including retrieval quality, prompt design, and response formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:12:13.457575Z",
     "iopub.status.busy": "2026-02-20T12:12:13.456940Z",
     "iopub.status.idle": "2026-02-20T12:12:15.114281Z",
     "shell.execute_reply": "2026-02-20T12:12:15.112696Z"
    }
   },
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from langsmith import traceable, trace\n",
    "from langsmith.wrappers import wrap_anthropic\n",
    "\n",
    "client = wrap_anthropic(anthropic.Anthropic())\n",
    "\n",
    "# Version your system prompts explicitly. This lets you test prompt changes\n",
    "# against the same evaluation suite and compare results systematically —\n",
    "# rather than editing inline and losing track of what changed.\n",
    "SYSTEM_PROMPT_V1 = (\n",
    "    \"You are a helpful mortgage lending assistant. Answer the borrower's \"\n",
    "    \"question using ONLY the provided context. Be specific, cite numbers \"\n",
    "    \"when available, and always recommend speaking with a loan officer for \"\n",
    "    \"personalized advice. Never guarantee approval, specific rates, or \"\n",
    "    \"outcomes. Use hedging language like 'typically', 'generally', and \"\n",
    "    \"'may vary based on your situation'.\"\n",
    ")\n",
    "\n",
    "@traceable(name=\"ask_mortgage_assistant\")\n",
    "def ask_mortgage_assistant(question: str, n_results: int = 2,\n",
    "                           system_prompt: str = SYSTEM_PROMPT_V1) -> dict:\n",
    "    \"\"\"Query the mortgage assistant RAG pipeline.\n",
    "    \n",
    "    Returns a dict with 'answer', 'context', and 'retrieval_context' keys.\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant documents (traced as \"tool\" run)\n",
    "    with trace(name=\"chromadb_retrieval\", run_type=\"tool\",\n",
    "               inputs={\"question\": question, \"n_results\": n_results}) as retrieval_run:\n",
    "        results = collection.query(\n",
    "            query_texts=[question],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        context_docs = results[\"documents\"][0]\n",
    "        retrieval_context = context_docs  # Keep as list for deepeval\n",
    "        context_text = \"\\n\\n---\\n\\n\".join(context_docs)\n",
    "        retrieval_run.outputs = {\"num_docs\": len(context_docs), \"documents\": context_docs}\n",
    "    \n",
    "    # Step 2: Generate response with Claude (auto-traced by wrap_anthropic)\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=1024,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context:\\n{context_text}\\n\\nQuestion: {question}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    answer = message.content[0].text\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"context\": context_text,\n",
    "        \"retrieval_context\": retrieval_context\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:12:15.118345Z",
     "iopub.status.busy": "2026-02-20T12:12:15.118000Z",
     "iopub.status.idle": "2026-02-20T12:12:20.333356Z",
     "shell.execute_reply": "2026-02-20T12:12:20.332299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What credit score do I need for an FHA loan?\n",
      "\n",
      "Answer:\n",
      "Based on the provided guidelines, for an FHA loan you typically need:\n",
      "\n",
      "- **Minimum credit score of 580** for a 3.5% down payment\n",
      "- **Credit score of 500-579** with a 10% down payment required\n",
      "\n",
      "FHA loans generally offer more flexible qualification guidelines compared to conventional loans, making them accessible to borrowers with lower credit scores. However, keep in mind that FHA loans require mortgage insurance premium (MIP) for the life of the loan regardless of how much equity you build.\n",
      "\n",
      "The specific credit score requirements may vary based on your overall financial situation and the lender's additional requirements. I'd recommend speaking with a loan officer who can review your complete financial profile and help determine the best loan option for your circumstances.\n",
      "\n",
      "--- Retrieved 2 document(s) ---\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample question\n",
    "result = ask_mortgage_assistant(\"What credit score do I need for an FHA loan?\")\n",
    "\n",
    "print(\"Question: What credit score do I need for an FHA loan?\")\n",
    "print(f\"\\nAnswer:\\n{result['answer']}\")\n",
    "print(f\"\\n--- Retrieved {len(result['retrieval_context'])} document(s) ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating with deepeval\n",
    "\n",
    "Now that we have a working RAG pipeline, we need to answer: **is it any good?**\n",
    "\n",
    "deepeval provides several LLM-as-judge metrics out of the box:\n",
    "\n",
    "| Metric | What It Measures | Why It Matters |\n",
    "|--------|-----------------|----------------|\n",
    "| **Faithfulness** | Is the answer supported by the retrieved context? | Catches hallucinations |\n",
    "| **Answer Relevancy** | Does the answer address the question asked? | Catches tangential responses |\n",
    "| **Contextual Precision** | Are the most relevant documents ranked first? | Measures retrieval quality |\n",
    "| **Contextual Recall** | Does the context contain enough info to answer? | Catches retrieval gaps |\n",
    "\n",
    "Each metric uses an LLM (Claude, in our case) as a **judge** — it reads the question, context, and answer, then renders a **binary PASS/FAIL verdict**. We enable `strict_mode` so there's no ambiguity: every metric either passes or fails, just like a unit test assertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:12:20.335981Z",
     "iopub.status.busy": "2026-02-20T12:12:20.335662Z",
     "iopub.status.idle": "2026-02-20T12:12:23.550572Z",
     "shell.execute_reply": "2026-02-20T12:12:23.548230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge model and generic metrics configured (strict_mode=True).\n"
     ]
    }
   ],
   "source": [
    "from deepeval.models import AnthropicModel\n",
    "from deepeval.metrics import (\n",
    "    FaithfulnessMetric,\n",
    "    AnswerRelevancyMetric,\n",
    "    ContextualPrecisionMetric,\n",
    "    # ContextualRecallMetric — excluded from this workshop.\n",
    "    #\n",
    "    # ContextualRecall checks whether each sentence in expected_output can\n",
    "    # be directly attributed to the retrieval_context.  With our setup\n",
    "    # (n_results=2 out of 4 docs, plus hand-written expected outputs that\n",
    "    # include generic guidance like \"speak with a loan officer\" and specific\n",
    "    # details like \"600 credit score\" that don't appear verbatim in any\n",
    "    # doc), 3 of 4 test cases fail — not because retrieval is bad, but\n",
    "    # because the metric demands strict citation and our expected outputs\n",
    "    # are written for answer quality, not retrieval sufficiency.\n",
    "    #\n",
    "    # Faithfulness + AnswerRelevancy + ContextualPrecision already cover\n",
    "    # the dimensions we care about for this demo.  If you need to measure\n",
    "    # retrieval coverage in production, build expected_outputs that are\n",
    "    # derived from the retrieved docs rather than written independently.\n",
    ")\n",
    "\n",
    "# Set up Claude as the judge model\n",
    "judge = AnthropicModel(model=\"claude-sonnet-4-20250514\")\n",
    "\n",
    "# Instantiate metrics with strict_mode=True for binary pass/fail verdicts\n",
    "# strict_mode makes the score 0 (fail) or 1 (pass) — no continuous values\n",
    "faithfulness = FaithfulnessMetric(model=judge, threshold=0.7, strict_mode=True)\n",
    "relevancy = AnswerRelevancyMetric(model=judge, threshold=0.7, strict_mode=True)\n",
    "precision = ContextualPrecisionMetric(model=judge, threshold=0.7, strict_mode=True)\n",
    "\n",
    "generic_metrics = [faithfulness, relevancy, precision]\n",
    "print(\"Judge model and generic metrics configured (strict_mode=True).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:12:23.555909Z",
     "iopub.status.busy": "2026-02-20T12:12:23.555499Z",
     "iopub.status.idle": "2026-02-20T12:12:51.566342Z",
     "shell.execute_reply": "2026-02-20T12:12:51.564599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Straightforward factual] Generated answer (659 chars)\n",
      "[Cross-topic (tests retrieval)] Generated answer (1284 chars)\n",
      "[Multi-document (VA + FHA)] Generated answer (1550 chars)\n",
      "[Compliance-sensitive] Generated answer (1399 chars)\n",
      "\n",
      "Created 4 test cases.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Define test questions that exercise different retrieval scenarios\n",
    "test_questions = [\n",
    "    {\n",
    "        \"input\": \"What is the minimum down payment for a conventional loan for first-time buyers?\",\n",
    "        \"expected_output\": \"The minimum down payment for a conventional loan for first-time buyers is 3%.\",\n",
    "        \"scenario\": \"Straightforward factual\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"How does the escrow process affect my interest rate?\",\n",
    "        \"expected_output\": \"Escrow does not directly affect your interest rate. Escrow accounts hold funds for taxes and insurance, while your rate is determined by market conditions and your loan terms.\",\n",
    "        \"scenario\": \"Cross-topic (tests retrieval)\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"I'm a veteran with a 600 credit score and no savings for a down payment. What are my options?\",\n",
    "        \"expected_output\": \"As a veteran, you may be eligible for a VA loan which requires no down payment. With a 600 credit score, you may also qualify for an FHA loan with 3.5% down. Speak with a loan officer for personalized guidance.\",\n",
    "        \"scenario\": \"Multi-document (VA + FHA)\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Can you guarantee I'll be approved for a mortgage if my credit score is above 700?\",\n",
    "        \"expected_output\": \"No lender can guarantee approval based on credit score alone. While a 700+ score is generally strong, approval depends on multiple factors including income, debt-to-income ratio, employment history, and the specific property. Please consult a loan officer for a personalized assessment.\",\n",
    "        \"scenario\": \"Compliance-sensitive\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate answers and build test cases\n",
    "test_cases = []\n",
    "for q in test_questions:\n",
    "    result = ask_mortgage_assistant(q[\"input\"])\n",
    "    tc = LLMTestCase(\n",
    "        input=q[\"input\"],\n",
    "        actual_output=result[\"answer\"],\n",
    "        expected_output=q[\"expected_output\"],\n",
    "        retrieval_context=result[\"retrieval_context\"]\n",
    "    )\n",
    "    test_cases.append(tc)\n",
    "    print(f\"[{q['scenario']}] Generated answer ({len(result['answer'])} chars)\")\n",
    "\n",
    "print(f\"\\nCreated {len(test_cases)} test cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined: get_metric_name, evaluate_and_trace, run_parallel_evaluation\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "from langsmith import trace\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from copy import copy\n",
    "import traceback\n",
    "\n",
    "\n",
    "def get_metric_name(metric):\n",
    "    \"\"\"Get display name from a deepeval metric.\"\"\"\n",
    "    if hasattr(metric, \"name\") and metric.__class__.__name__ == \"GEval\":\n",
    "        return metric.name\n",
    "    return metric.__class__.__name__.replace(\"Metric\", \"\")\n",
    "\n",
    "\n",
    "def _new_event_loop():\n",
    "    \"\"\"Create an asyncio event loop for a worker thread.\n",
    "\n",
    "    deepeval metrics call asyncio internally (via the Anthropic SDK), so\n",
    "    every ThreadPoolExecutor worker needs its own event loop — the main\n",
    "    thread's loop isn't visible from worker threads.\n",
    "\n",
    "    We call the *original* asyncio.new_event_loop (saved as\n",
    "    asyncio._orig_new_event_loop in cell 1) rather than the patched\n",
    "    version.  This matters when the notebook is re-run: the patched\n",
    "    version might reference itself if the guard failed, causing infinite\n",
    "    recursion.  getattr with a fallback keeps this robust either way.\n",
    "    \"\"\"\n",
    "    factory = getattr(asyncio, '_orig_new_event_loop', asyncio.new_event_loop)\n",
    "    loop = factory()\n",
    "    loop.set_exception_handler(lambda _loop, _ctx: None)\n",
    "    return loop\n",
    "\n",
    "\n",
    "def evaluate_and_trace(index, test_case, metrics, trace_name, section, label):\n",
    "    \"\"\"Evaluate a test case against metrics with LangSmith tracing.\n",
    "\n",
    "    Sets up a fresh asyncio event loop for the current thread since deepeval\n",
    "    metrics use asyncio internally and ThreadPoolExecutor threads lack one.\n",
    "\n",
    "    Uses copy() instead of deepcopy() because deepeval metrics hold a\n",
    "    reference to an AnthropicModel wrapping httpx.Client, which contains\n",
    "    _thread.RLock objects that cannot be pickled (deepcopy fails).  Shallow\n",
    "    copy is safe here: measure() only assigns new scalar attributes (score,\n",
    "    reason, success) on the copy — it doesn't mutate shared containers on\n",
    "    the original.  The shared httpx.Client is thread-safe by design.\n",
    "    \"\"\"\n",
    "    loop = _new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    try:\n",
    "        with trace(\n",
    "            name=trace_name, run_type=\"chain\",\n",
    "            inputs={\"input\": test_case.input[:200], \"label\": label},\n",
    "            metadata={\"section\": section, \"label\": label}\n",
    "        ) as eval_run:\n",
    "            row = {\"label\": label}\n",
    "            for metric in metrics:\n",
    "                m = copy(metric)\n",
    "                m.measure(test_case, _show_indicator=False)\n",
    "                row[get_metric_name(m)] = \"PASS\" if m.score == 1 else \"FAIL\"\n",
    "            eval_run.outputs = {k: v for k, v in row.items() if k != \"label\"}\n",
    "        return index, row\n",
    "    finally:\n",
    "        loop.close()\n",
    "\n",
    "\n",
    "def run_parallel_evaluation(items, eval_func, max_workers=None):\n",
    "    \"\"\"Run eval_func(i, item) in parallel across items. Returns list of results.\"\"\"\n",
    "    results = [None] * len(items)\n",
    "    errors = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers or len(items)) as executor:\n",
    "        futures = {executor.submit(eval_func, i, item): i for i, item in enumerate(items)}\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                idx, row = future.result()\n",
    "                results[idx] = row\n",
    "                print(f\"  Scored: {row.get('label', idx)}\")\n",
    "            except Exception as e:\n",
    "                idx = futures[future]\n",
    "                print(f\"  ERROR on item {idx}: {type(e).__name__}: {e}\")\n",
    "                traceback.print_exc()\n",
    "                errors.append((idx, e))\n",
    "    if errors:\n",
    "        raise RuntimeError(f\"{len(errors)} evaluation(s) failed. First error: {errors[0][1]}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Helper functions defined: get_metric_name, evaluate_and_trace, run_parallel_evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606b0d440b244be7a418a82cb7b19ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Copy succeeded: FaithfulnessMetric\n",
      "2. Has score attr before measure: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. measure() completed. Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "  # Debug: test single metric copy + measure (no parallelism, no tracing)                                                                                \n",
    "  from copy import copy                                                                                                                                  \n",
    "   \n",
    "  tc = test_cases[0]                                                                                                                                     \n",
    "  m = copy(generic_metrics[0])                                                                                                                         \n",
    "  print(f\"1. Copy succeeded: {type(m).__name__}\")\n",
    "  print(f\"2. Has score attr before measure: {hasattr(m, 'score')}\")\n",
    "\n",
    "  try:\n",
    "      m.measure(tc)\n",
    "      print(f\"3. measure() completed. Score: {m.score}\")\n",
    "  except Exception as e:\n",
    "      import traceback\n",
    "      print(f\"3. measure() FAILED: {type(e).__name__}: {e}\")\n",
    "      traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:12:51.571690Z",
     "iopub.status.busy": "2026-02-20T12:12:51.571346Z",
     "iopub.status.idle": "2026-02-20T12:15:45.733267Z",
     "shell.execute_reply": "2026-02-20T12:15:45.730761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scored: Straightforward factual\n",
      "  Scored: Cross-topic (tests retrieval)\n",
      "  Scored: Multi-document (VA + FHA)\n",
      "  Scored: Compliance-sensitive\n",
      "\n",
      "--- Generic Metric Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>AnswerRelevancy</th>\n",
       "      <th>ContextualPrecision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Straightforward factual</th>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross-topic (tests retrieval)</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-document (VA + FHA)</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compliance-sensitive</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Faithfulness AnswerRelevancy ContextualPrecision\n",
       "scenario                                                                      \n",
       "Straightforward factual               PASS            FAIL                PASS\n",
       "Cross-topic (tests retrieval)         PASS            PASS                PASS\n",
       "Multi-document (VA + FHA)             PASS            PASS                PASS\n",
       "Compliance-sensitive                  PASS            PASS                PASS"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_generic(i, tc):\n",
    "    return evaluate_and_trace(i, tc, generic_metrics, \"deepeval_generic_metrics\",\n",
    "                              \"generic_metrics\", test_questions[i][\"scenario\"])\n",
    "\n",
    "results_data = run_parallel_evaluation(test_cases, eval_generic)\n",
    "df_generic = pd.DataFrame(results_data).set_index(\"label\")\n",
    "df_generic.index.name = \"scenario\"\n",
    "print(\"\\n--- Generic Metric Results ---\")\n",
    "df_generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Gap: What Generic Metrics Miss\n",
    "\n",
    "Look at the results above. The generic metrics likely show PASS across the board — the system retrieves relevant context and generates faithful, relevant answers.\n",
    "\n",
    "But consider: in mortgage lending, a response can **pass faithfulness and relevancy** while still being:\n",
    "\n",
    "- **Regulatorily problematic** — making promises or guarantees about approval\n",
    "- **Missing disclaimers** — quoting rates without noting they're estimates\n",
    "- **Vague and unactionable** — technically correct but useless to the borrower\n",
    "- **Tonally inappropriate** — too casual for compliance, too stiff for customer service\n",
    "\n",
    "Generic metrics measure the **mechanics** of RAG (did it retrieve? did it stay faithful?). They don't measure whether the response is **safe to send to a customer** in a regulated industry.\n",
    "\n",
    "That's where custom metrics come in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Custom Metrics\n",
    "\n",
    "Generic metrics tell you whether the RAG pipeline *works*. Custom metrics tell you whether it works **for your business**.\n",
    "\n",
    "deepeval's `GEval` lets you define evaluation criteria in plain English. The LLM judge then evaluates responses against *your* rubric and renders a **PASS or FAIL verdict** — encoding institutional knowledge, compliance requirements, and quality standards into automated assertions.\n",
    "\n",
    "We'll build two custom metrics:\n",
    "1. **Regulatory Compliance** — does the response avoid making prohibited claims?\n",
    "2. **Actionability** — does the response give the borrower a clear next step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:15:45.745715Z",
     "iopub.status.busy": "2026-02-20T12:15:45.745122Z",
     "iopub.status.idle": "2026-02-20T12:15:45.753522Z",
     "shell.execute_reply": "2026-02-20T12:15:45.751551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regulatory Compliance metric defined with 5 evaluation steps (strict_mode=True).\n"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "# Custom Metric 1: Regulatory Compliance\n",
    "regulatory_compliance = GEval(\n",
    "    name=\"Regulatory Compliance\",\n",
    "    model=judge,\n",
    "    threshold=0.7,\n",
    "    strict_mode=True,  # Binary PASS/FAIL — no continuous scores\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "        LLMTestCaseParams.RETRIEVAL_CONTEXT,\n",
    "    ],\n",
    "    evaluation_steps=[\n",
    "        \"Check that the response does NOT guarantee loan approval, specific rates, or specific outcomes for the borrower.\",\n",
    "        \"Verify the response uses hedging language ('typically', 'generally', 'may vary') rather than definitive statements about what WILL happen.\",\n",
    "        \"Confirm the response does NOT quote specific interest rates as currently available without noting they are estimates subject to change.\",\n",
    "        \"Check that the response recommends speaking with a loan officer or qualified professional for personalized advice.\",\n",
    "        \"Verify the response does NOT make binding commitments or promises on behalf of the lending institution.\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Regulatory Compliance metric defined with 5 evaluation steps (strict_mode=True).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:15:45.757282Z",
     "iopub.status.busy": "2026-02-20T12:15:45.757059Z",
     "iopub.status.idle": "2026-02-20T12:15:45.761981Z",
     "shell.execute_reply": "2026-02-20T12:15:45.760984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionability metric defined with 4 evaluation steps (strict_mode=True).\n"
     ]
    }
   ],
   "source": [
    "# Custom Metric 2: Actionability\n",
    "actionability = GEval(\n",
    "    name=\"Actionability\",\n",
    "    model=judge,\n",
    "    threshold=0.7,\n",
    "    strict_mode=True,  # Binary PASS/FAIL — no continuous scores\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "    ],\n",
    "    evaluation_steps=[\n",
    "        \"Assess whether the response provides specific, concrete information rather than vague generalities.\",\n",
    "        \"Check that the response includes clear next steps the borrower can take.\",\n",
    "        \"Verify the response includes relevant numerical values (percentages, dollar ranges, timeframes) where applicable.\",\n",
    "        \"Confirm the response gives the borrower a clear path forward, even if that path is 'contact a loan officer for your specific situation'.\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Actionability metric defined with 4 evaluation steps (strict_mode=True).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:15:45.764405Z",
     "iopub.status.busy": "2026-02-20T12:15:45.764171Z",
     "iopub.status.idle": "2026-02-20T12:19:11.001113Z",
     "shell.execute_reply": "2026-02-20T12:19:10.998783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scored: Straightforward factual\n",
      "  Scored: Cross-topic (tests retrieval)\n",
      "  Scored: Multi-document (VA + FHA)\n",
      "  Scored: Compliance-sensitive\n",
      "\n",
      "--- Full Metric Results (Generic + Custom) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>AnswerRelevancy</th>\n",
       "      <th>ContextualPrecision</th>\n",
       "      <th>Regulatory Compliance</th>\n",
       "      <th>Actionability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Straightforward factual</th>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross-topic (tests retrieval)</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-document (VA + FHA)</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compliance-sensitive</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Faithfulness AnswerRelevancy  \\\n",
       "scenario                                                     \n",
       "Straightforward factual               PASS            FAIL   \n",
       "Cross-topic (tests retrieval)         PASS            PASS   \n",
       "Multi-document (VA + FHA)             PASS            PASS   \n",
       "Compliance-sensitive                  PASS            PASS   \n",
       "\n",
       "                              ContextualPrecision Regulatory Compliance  \\\n",
       "scenario                                                                  \n",
       "Straightforward factual                      PASS                  FAIL   \n",
       "Cross-topic (tests retrieval)                PASS                  PASS   \n",
       "Multi-document (VA + FHA)                    PASS                  PASS   \n",
       "Compliance-sensitive                         PASS                  PASS   \n",
       "\n",
       "                              Actionability  \n",
       "scenario                                     \n",
       "Straightforward factual                PASS  \n",
       "Cross-topic (tests retrieval)          PASS  \n",
       "Multi-document (VA + FHA)              PASS  \n",
       "Compliance-sensitive                   PASS  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine generic + custom metrics\n",
    "all_metrics = generic_metrics + [regulatory_compliance, actionability]\n",
    "\n",
    "def eval_all(i, tc):\n",
    "    return evaluate_and_trace(i, tc, all_metrics, \"deepeval_all_metrics\",\n",
    "                              \"all_metrics\", test_questions[i][\"scenario\"])\n",
    "\n",
    "full_results = run_parallel_evaluation(test_cases, eval_all)\n",
    "df_full = pd.DataFrame(full_results).set_index(\"label\")\n",
    "df_full.index.name = \"scenario\"\n",
    "print(\"\\n--- Full Metric Results (Generic + Custom) ---\")\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:11.005167Z",
     "iopub.status.busy": "2026-02-20T12:19:11.004803Z",
     "iopub.status.idle": "2026-02-20T12:19:58.475437Z",
     "shell.execute_reply": "2026-02-20T12:19:58.472636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Contrived Example: Faithful but Non-Compliant ---\n",
      "\n",
      "Response: \"With your 720 credit score, you'll definitely qualify for a conventional loan. Your rate will be aro...\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faithfulness</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnswerRelevancy</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ContextualPrecision</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regulatory Compliance</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Actionability</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  metric verdict\n",
       "0           Faithfulness    PASS\n",
       "1        AnswerRelevancy    PASS\n",
       "2    ContextualPrecision    PASS\n",
       "3  Regulatory Compliance    FAIL\n",
       "4          Actionability    PASS"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contrived example: a response that is faithful but regulatorily problematic\n",
    "problematic_response = (\n",
    "    \"With your 720 credit score, you'll definitely qualify for a conventional \"\n",
    "    \"loan. Your rate will be around 6.5%, and with 5% down on a $400,000 home \"\n",
    "    \"your monthly payment will be approximately $2,275. You'll be approved \"\n",
    "    \"within 2 weeks. The PMI will cost you about $150/month until you hit 20% \"\n",
    "    \"equity, which should take about 7 years at current appreciation rates.\"\n",
    ")\n",
    "\n",
    "problematic_tc = LLMTestCase(\n",
    "    input=\"I have a 720 credit score and want to buy a $400,000 home. What should I expect?\",\n",
    "    actual_output=problematic_response,\n",
    "    expected_output=\"With a 720 credit score, you may qualify for several loan options. Speak with a loan officer for rates and terms specific to your situation.\",\n",
    "    retrieval_context=[MORTGAGE_DOCS[\"loan_types\"]]\n",
    ")\n",
    "\n",
    "# Score with all metrics using helpers\n",
    "contrast_results = {\"metric\": [], \"verdict\": []}\n",
    "for metric in all_metrics:\n",
    "    m = copy(metric)\n",
    "    m.measure(problematic_tc, _show_indicator=False)\n",
    "    contrast_results[\"metric\"].append(get_metric_name(m))\n",
    "    contrast_results[\"verdict\"].append(\"PASS\" if m.score == 1 else \"FAIL\")\n",
    "\n",
    "df_contrast = pd.DataFrame(contrast_results)\n",
    "print(\"--- Contrived Example: Faithful but Non-Compliant ---\")\n",
    "print(f\"\\nResponse: \\\"{problematic_response[:100]}...\\\"\")\n",
    "df_contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "The contrived response **passes** the generic metrics — it's relevant to the question and mostly faithful to the context (conventional loan info, PMI details). But it **fails** the regulatory compliance metric because it:\n",
    "\n",
    "- Guarantees approval (\"you'll definitely qualify\")\n",
    "- Quotes a specific rate as certain (\"your rate will be around 6.5%\")\n",
    "- Promises a timeline (\"approved within 2 weeks\")\n",
    "- Makes predictions about appreciation rates\n",
    "\n",
    "In a regulated industry, this response would be a compliance violation. Generic metrics can't catch this — they measure RAG mechanics, not business requirements. The binary PASS/FAIL format makes the divergence immediately clear: generic metrics say go, custom metrics say stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway\n",
    "\n",
    "Custom metrics encode **tribal knowledge** into automated assertions. The 5 evaluation steps in our regulatory compliance metric represent rules that every loan officer knows intuitively — but that a generic LLM metric has no reason to check.\n",
    "\n",
    "Building these metrics is a **governance activity**: compliance teams, product owners, and subject matter experts define what \"good\" looks like, and the evaluation pipeline enforces it automatically on every response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Golden Dataset and Acceptance Criteria\n",
    "\n",
    "A golden dataset is your **acceptance criteria** for the AI system. It's a curated set of examples where you know what a good answer looks like — and, critically, what a *bad* answer looks like.\n",
    "\n",
    "A strong golden dataset includes:\n",
    "- **Positive examples** — responses that meet your quality bar (the system should score these highly)\n",
    "- **Negative examples** — responses that violate your standards (the system should score these poorly)\n",
    "\n",
    "This is how you prevent your evaluation from becoming a rubber stamp. If your metrics can't distinguish good from bad, they're not measuring anything useful.\n",
    "\n",
    "The golden dataset also serves as a **regression test**: when you change the prompt, swap models, or update retrieval, you re-run against the golden dataset to verify you haven't degraded quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:58.480410Z",
     "iopub.status.busy": "2026-02-20T12:19:58.479736Z",
     "iopub.status.idle": "2026-02-20T12:19:58.532900Z",
     "shell.execute_reply": "2026-02-20T12:19:58.531813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden dataset: 12 examples (8 positive, 4 negative)\n"
     ]
    }
   ],
   "source": [
    "from deepeval.dataset import EvaluationDataset, Golden\n",
    "\n",
    "# Define 12 golden examples: 8 positive (compliant, actionable) + 4 negative\n",
    "golden_examples = [\n",
    "    # --- POSITIVE EXAMPLES (should score well) ---\n",
    "    Golden(\n",
    "        input=\"What credit score do I need for a conventional loan?\",\n",
    "        expected_output=(\n",
    "            \"Generally, conventional loans require a minimum credit score of 620. \"\n",
    "            \"First-time buyers may qualify with as little as 3% down, while repeat \"\n",
    "            \"buyers typically need 5% or more. Keep in mind that your specific rate \"\n",
    "            \"and terms will depend on your full financial profile. I'd recommend \"\n",
    "            \"speaking with a loan officer to discuss your options.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"Conventional Loans: Available for borrowers with credit scores of 620 or higher. \"\n",
    "            \"Down payment requirements start at 3% for first-time buyers and 5% for repeat buyers.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"How long does a rate lock last?\",\n",
    "        expected_output=(\n",
    "            \"Standard rate locks are typically 30 days at no additional cost. Extended \"\n",
    "            \"lock periods are available: 45-day locks generally carry a 0.125% fee, and \"\n",
    "            \"60-day locks a 0.250% fee. If your lock expires before closing, you may need \"\n",
    "            \"to re-lock at current market rates. Your loan officer can help you choose \"\n",
    "            \"the right lock period for your timeline.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"Standard Lock Periods: 30-day locks are included at no additional cost. \"\n",
    "            \"45-day locks carry a 0.125% fee. 60-day locks carry a 0.250% fee.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"What are closing costs?\",\n",
    "        expected_output=(\n",
    "            \"Closing costs typically range from 2% to 5% of the loan amount. They \"\n",
    "            \"generally include origination fees, an appraisal fee ($400-700), title \"\n",
    "            \"search and insurance, recording fees, prepaid interest, and initial escrow \"\n",
    "            \"deposits. Some of these costs may be negotiable — ask your loan officer \"\n",
    "            \"about lender credits or seller concessions that could reduce your \"\n",
    "            \"out-of-pocket expenses.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"Closing Costs: Typically range from 2% to 5% of the loan amount. Include: \"\n",
    "            \"origination fees, appraisal fee ($400-700), title search and insurance, \"\n",
    "            \"recording fees, prepaid interest, and initial escrow deposits.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"Am I eligible for a VA loan?\",\n",
    "        expected_output=(\n",
    "            \"VA loans are available to eligible veterans, active-duty service members, \"\n",
    "            \"and surviving spouses. Key benefits include no down payment requirement \"\n",
    "            \"and no private mortgage insurance. A funding fee applies, ranging from \"\n",
    "            \"1.25% to 3.3% depending on your service history and down payment. \"\n",
    "            \"I'd recommend contacting a loan officer who specializes in VA loans to \"\n",
    "            \"verify your eligibility and discuss your specific situation.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"VA Loans: Available to eligible veterans, active-duty service members, and \"\n",
    "            \"surviving spouses. No down payment required. No private mortgage insurance.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"What documents do I need for income verification?\",\n",
    "        expected_output=(\n",
    "            \"For income verification, you'll generally need at least 2 years of tax \"\n",
    "            \"returns, recent pay stubs covering the last 30 days, and W-2s or 1099s. \"\n",
    "            \"If you're self-employed, expect to provide 2 years of business tax returns \"\n",
    "            \"and a year-to-date profit and loss statement. Your employer will also \"\n",
    "            \"undergo a verbal verification of employment within 10 business days of \"\n",
    "            \"closing. Your loan officer can provide a complete checklist tailored \"\n",
    "            \"to your situation.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"Income Verification: All income must be documented with at least 2 years of \"\n",
    "            \"tax returns, recent pay stubs (30 days), and W-2s or 1099s.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"What happens if the appraisal is lower than the purchase price?\",\n",
    "        expected_output=(\n",
    "            \"If the appraisal comes in below the purchase price, you generally have \"\n",
    "            \"several options: renegotiating the purchase price with the seller, increasing \"\n",
    "            \"your down payment to cover the gap, requesting a reconsideration of value \"\n",
    "            \"from the appraiser, or canceling the transaction per your contract terms. \"\n",
    "            \"Your loan officer and real estate agent can help you evaluate which \"\n",
    "            \"option makes the most sense for your situation.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"If the appraisal comes in below the purchase price, options include: \"\n",
    "            \"renegotiating the price, increasing down payment, requesting a reconsideration \"\n",
    "            \"of value, or canceling the transaction per contract terms.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"Can I remove PMI from my conventional loan?\",\n",
    "        expected_output=(\n",
    "            \"Yes, PMI on conventional loans can typically be removed once your \"\n",
    "            \"loan-to-value ratio reaches 78%, which means you have at least 22% \"\n",
    "            \"equity in your home. This can happen through regular payments, home \"\n",
    "            \"value appreciation, or a combination. Contact your loan servicer to \"\n",
    "            \"discuss the specific process and any requirements for PMI removal \"\n",
    "            \"on your loan.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"Private mortgage insurance (PMI) is required when down payment is less than 20%. \"\n",
    "            \"PMI can be removed once the loan-to-value ratio reaches 78%.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"What is the float-down option for rate locks?\",\n",
    "        expected_output=(\n",
    "            \"If market rates drop after you've locked your rate, a one-time \"\n",
    "            \"float-down option may be available. This typically carries a 0.125% \"\n",
    "            \"fee and requires a minimum rate improvement of 0.25% to exercise. \"\n",
    "            \"Not all lock agreements include this option, so ask your loan officer \"\n",
    "            \"about float-down availability when you lock your rate.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"If market rates fall after locking, a one-time float-down option may be \"\n",
    "            \"available for a 0.125% fee, subject to a minimum rate improvement of 0.25%.\"\n",
    "        ]\n",
    "    ),\n",
    "\n",
    "    # --- NEGATIVE EXAMPLES (should score poorly) ---\n",
    "    Golden(\n",
    "        input=\"Will I be approved for a mortgage?\",\n",
    "        expected_output=(\n",
    "            \"Yes, with a decent credit score you'll definitely be approved. Most \"\n",
    "            \"people with scores above 620 get approved without any issues. Your \"\n",
    "            \"approval is practically guaranteed as long as you have steady income.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"Conventional Loans: Available for borrowers with credit scores of 620 or higher.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"What interest rate will I get?\",\n",
    "        expected_output=(\n",
    "            \"Rates vary. It depends on a lot of factors. You should probably \"\n",
    "            \"talk to someone about it. There are different types of loans available.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"Rate quotes provided during initial consultation are estimates only and do not \"\n",
    "            \"constitute a rate lock. Rates are not guaranteed until a formal lock confirmation \"\n",
    "            \"is issued in writing.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"Do you offer zero-closing-cost mortgages?\",\n",
    "        expected_output=(\n",
    "            \"Yes, we offer a special zero-closing-cost mortgage program where all \"\n",
    "            \"fees are waived for qualified borrowers. This is our premium program \"\n",
    "            \"that includes free appraisals, no origination fees, and waived title \"\n",
    "            \"insurance costs. Apply today to lock in this exclusive offer.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"Closing Costs: Typically range from 2% to 5% of the loan amount.\"\n",
    "        ]\n",
    "    ),\n",
    "    Golden(\n",
    "        input=\"What's the current 30-year fixed rate?\",\n",
    "        expected_output=(\n",
    "            \"The current 30-year fixed rate is 6.75%. Lock in today before \"\n",
    "            \"rates go up! This is the lowest rate we've offered in months \"\n",
    "            \"and it won't last. Act now to secure your rate.\"\n",
    "        ),\n",
    "        context=[\n",
    "            \"Rate quotes provided during initial consultation are estimates only and do not \"\n",
    "            \"constitute a rate lock.\"\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Label them for analysis\n",
    "golden_labels = [\"positive\"] * 8 + [\"negative\"] * 4\n",
    "\n",
    "dataset = EvaluationDataset(goldens=golden_examples)\n",
    "print(f\"Golden dataset: {len(golden_examples)} examples ({sum(1 for l in golden_labels if l == 'positive')} positive, {sum(1 for l in golden_labels if l == 'negative')} negative)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Human Annotation Workflow\n",
    "\n",
    "In practice, building a golden dataset is a **team activity**:\n",
    "\n",
    "1. **Collect** real customer questions from support logs, chat transcripts, or stakeholder interviews\n",
    "2. **Generate** candidate responses from your AI system\n",
    "3. **Rate** each response: have 2-3 team members independently score quality\n",
    "4. **Discuss** disagreements — these reveal where your quality standards are ambiguous\n",
    "5. **Lock** the consensus ratings as your golden dataset\n",
    "\n",
    "The golden dataset isn't static — it evolves as you discover new edge cases, refine your quality standards, and encounter new types of customer questions. Think of it as a living acceptance criteria document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:58.545606Z",
     "iopub.status.busy": "2026-02-20T12:19:58.545343Z",
     "iopub.status.idle": "2026-02-20T12:21:16.746010Z",
     "shell.execute_reply": "2026-02-20T12:21:16.743952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scored: positive\n",
      "  Scored: positive\n",
      "  Scored: negative\n",
      "  Scored: positive\n",
      "  Scored: positive\n",
      "  Scored: negative\n",
      "  Scored: positive\n",
      "  Scored: positive\n",
      "  Scored: positive\n",
      "  Scored: negative\n",
      "  Scored: negative\n",
      "  Scored: positive\n",
      "\n",
      "--- Golden Dataset Evaluation ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Regulatory Compliance</th>\n",
       "      <th>Actionability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>positive</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negative</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>negative</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>negative</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>negative</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label Regulatory Compliance Actionability\n",
       "0   positive                  PASS          PASS\n",
       "1   positive                  PASS          PASS\n",
       "2   positive                  PASS          PASS\n",
       "3   positive                  FAIL          PASS\n",
       "4   positive                  PASS          PASS\n",
       "5   positive                  PASS          FAIL\n",
       "6   positive                  PASS          PASS\n",
       "7   positive                  FAIL          PASS\n",
       "8   negative                  FAIL          FAIL\n",
       "9   negative                  FAIL          FAIL\n",
       "10  negative                  FAIL          FAIL\n",
       "11  negative                  FAIL          FAIL"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the golden dataset using our custom metrics\n",
    "# We use the expected_output as the actual_output since these are pre-written examples\n",
    "custom_metrics = [regulatory_compliance, actionability]\n",
    "\n",
    "def eval_golden(i, golden):\n",
    "    tc = LLMTestCase(input=golden.input, actual_output=golden.expected_output,\n",
    "                     retrieval_context=golden.context)\n",
    "    return evaluate_and_trace(i, tc, custom_metrics, \"deepeval_golden_dataset\",\n",
    "                              \"golden_dataset\", golden_labels[i])\n",
    "\n",
    "golden_results = run_parallel_evaluation(golden_examples, eval_golden)\n",
    "df_golden = pd.DataFrame(golden_results)\n",
    "print(\"\\n--- Golden Dataset Evaluation ---\")\n",
    "df_golden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:21:16.751493Z",
     "iopub.status.busy": "2026-02-20T12:21:16.751061Z",
     "iopub.status.idle": "2026-02-20T12:21:16.776172Z",
     "shell.execute_reply": "2026-02-20T12:21:16.773521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regulatory Compliance:\n",
      "  Positive examples pass rate: 75%\n",
      "  Negative examples pass rate: 0%\n",
      "  -> Good separation. The metric distinguishes positive from negative examples.\n",
      "\n",
      "Actionability:\n",
      "  Positive examples pass rate: 88%\n",
      "  Negative examples pass rate: 0%\n",
      "  -> Good separation. The metric distinguishes positive from negative examples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do negative examples actually fail? Compare pass rates by label.\n",
    "for metric_name in [\"Regulatory Compliance\", \"Actionability\"]:\n",
    "    pos_pass = (df_golden[df_golden[\"label\"] == \"positive\"][metric_name] == \"PASS\").mean()\n",
    "    neg_pass = (df_golden[df_golden[\"label\"] == \"negative\"][metric_name] == \"PASS\").mean()\n",
    "    print(f\"{metric_name}:\")\n",
    "    print(f\"  Positive examples pass rate: {pos_pass:.0%}\")\n",
    "    print(f\"  Negative examples pass rate: {neg_pass:.0%}\")\n",
    "    if pos_pass > neg_pass + 0.2:\n",
    "        print(f\"  -> Good separation. The metric distinguishes positive from negative examples.\")\n",
    "    elif pos_pass > neg_pass:\n",
    "        print(f\"  -> Weak separation. Consider refining the metric's evaluation steps.\")\n",
    "    else:\n",
    "        print(f\"  -> No separation! The metric cannot distinguish good from bad. Needs redesign.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition: How Much Can We Trust These Scores?\n",
    "\n",
    "We now have metrics that *appear* to distinguish good responses from bad ones. But how do we know the automated judge agrees with what a **human expert** would say?\n",
    "\n",
    "This is the central question of AI evaluation: **validating the validator**. If your automated metric disagrees with human judgment on 40% of cases, it's not a reliable gatekeeper — no matter how sophisticated the rubric.\n",
    "\n",
    "In the next section, we'll quantify this agreement using **inter-rater reliability** — the same statistical framework used in medicine, psychology, and other fields where multiple raters must agree on subjective judgments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Inter-Rater Reliability — Validating the Validator\n",
    "\n",
    "In medicine, before a diagnostic test is trusted, researchers measure how often it agrees with expert clinicians. If a new blood test says \"positive\" when the doctor says \"negative\" 30% of the time, nobody uses that test.\n",
    "\n",
    "**The same principle applies to AI evaluation.** Your automated LLM judge is a diagnostic test. The \"disease\" is poor response quality. Before you trust it to gatekeep production, you need to measure how often it agrees with human experts.\n",
    "\n",
    "| Medical Analogy | AI Evaluation Equivalent |\n",
    "|-----------------|-------------------------|\n",
    "| Diagnostic test | Automated LLM metric |\n",
    "| Expert clinician | Human annotator |\n",
    "| Patient sample | AI-generated response |\n",
    "| Test positive/negative | Pass/fail threshold |\n",
    "| Sensitivity (TPR) | Catches bad responses when they're bad |\n",
    "| Specificity (TNR) | Lets good responses through when they're good |\n",
    "| Cohen's kappa | Agreement beyond chance |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Human Annotations\n",
    "\n",
    "In practice, you'd have compliance officers and product managers annotate a sample of responses. Here, we'll use pre-written responses with pre-assigned human labels to keep results stable across runs.\n",
    "\n",
    "The 20 traces below are designed with:\n",
    "- **7 clearly acceptable** — compliant, actionable, well-hedged\n",
    "- **5 clearly unacceptable** — guarantees, hallucinations, missing disclaimers\n",
    "- **8 borderline** — where reasonable people might disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:21:16.780904Z",
     "iopub.status.busy": "2026-02-20T12:21:16.780557Z",
     "iopub.status.idle": "2026-02-20T12:21:16.811684Z",
     "shell.execute_reply": "2026-02-20T12:21:16.810513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 annotated traces:\n",
      "  Acceptable: 14\n",
      "  Unacceptable: 6\n"
     ]
    }
   ],
   "source": [
    "# 20 pre-written traces with human annotations\n",
    "# Each has: question, response, retrieval context, and human_label (acceptable/unacceptable)\n",
    "\n",
    "annotated_traces = [\n",
    "    # --- CLEARLY ACCEPTABLE (7) ---\n",
    "    {\n",
    "        \"input\": \"What's the minimum down payment for an FHA loan?\",\n",
    "        \"response\": (\n",
    "            \"For an FHA loan, the minimum down payment is generally 3.5% if your \"\n",
    "            \"credit score is 580 or higher. If your score falls between 500 and 579, \"\n",
    "            \"you may still qualify with a 10% down payment. These are general guidelines \"\n",
    "            \"— your loan officer can review your specific situation and help determine \"\n",
    "            \"the best option for you.\"\n",
    "        ),\n",
    "        \"context\": [\"FHA Loans: Minimum credit score of 580 for 3.5% down payment, or 500-579 with 10% down.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"How do I remove PMI?\",\n",
    "        \"response\": (\n",
    "            \"PMI on conventional loans can typically be removed once your loan-to-value \"\n",
    "            \"ratio reaches 78%, meaning you've built up at least 22% equity. This can \"\n",
    "            \"happen through your regular monthly payments or if your home's value \"\n",
    "            \"increases. Contact your loan servicer to discuss the specific removal \"\n",
    "            \"process for your loan.\"\n",
    "        ),\n",
    "        \"context\": [\"PMI can be removed once the loan-to-value ratio reaches 78%.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What documents do I need to apply for a mortgage?\",\n",
    "        \"response\": (\n",
    "            \"You'll generally need to provide at least 2 years of tax returns, \"\n",
    "            \"recent pay stubs from the last 30 days, W-2s or 1099s, and bank \"\n",
    "            \"statements for the most recent 2 months. If you're self-employed, \"\n",
    "            \"additional documentation such as business tax returns and a profit \"\n",
    "            \"and loss statement may be required. Your loan officer will provide \"\n",
    "            \"a complete checklist based on your specific loan type.\"\n",
    "        ),\n",
    "        \"context\": [\"Income Verification: All income must be documented with at least 2 years of tax returns, recent pay stubs (30 days), and W-2s or 1099s.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Can I use gift money for my down payment?\",\n",
    "        \"response\": (\n",
    "            \"Yes, gift funds from family members are generally permitted for down \"\n",
    "            \"payments. You'll typically need a signed gift letter confirming that \"\n",
    "            \"no repayment is expected. The funds will need to be documented and \"\n",
    "            \"sourced in your bank statements. Your loan officer can walk you through \"\n",
    "            \"the specific requirements for your loan program.\"\n",
    "        ),\n",
    "        \"context\": [\"Gift funds are permitted from family members with a signed gift letter confirming no repayment is expected.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is a Closing Disclosure?\",\n",
    "        \"response\": (\n",
    "            \"A Closing Disclosure is a document you'll receive at least 3 business \"\n",
    "            \"days before your scheduled closing. It details your final loan terms, \"\n",
    "            \"monthly payment amount, closing costs, and the cash you'll need to bring. \"\n",
    "            \"I'd strongly recommend comparing it carefully with your original Loan \"\n",
    "            \"Estimate to check for any unexpected changes. Your loan officer can help \"\n",
    "            \"explain any discrepancies.\"\n",
    "        ),\n",
    "        \"context\": [\"Federal law requires borrowers receive a Closing Disclosure at least 3 business days before closing.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What's the VA loan funding fee?\",\n",
    "        \"response\": (\n",
    "            \"The VA loan funding fee typically ranges from 1.25% to 3.3% of the \"\n",
    "            \"loan amount. The exact fee depends on factors such as your service \"\n",
    "            \"history, whether it's your first VA loan, and your down payment amount. \"\n",
    "            \"Some veterans may be exempt from the funding fee. A VA-specialized \"\n",
    "            \"loan officer can tell you your specific fee amount.\"\n",
    "        ),\n",
    "        \"context\": [\"Funding fee applies (ranges from 1.25% to 3.3% depending on service history and down payment).\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What are my options if my rate lock expires?\",\n",
    "        \"response\": (\n",
    "            \"If your rate lock expires before closing, you may need to re-lock at \"\n",
    "            \"current market rates, which could be higher or lower than your original \"\n",
    "            \"lock. Extension fees typically run about 0.125% per 7-day extension. \"\n",
    "            \"To help avoid expiration, try to submit all documentation promptly and \"\n",
    "            \"respond to underwriting requests within 48 hours. Talk to your loan \"\n",
    "            \"officer if you're concerned about your timeline.\"\n",
    "        ),\n",
    "        \"context\": [\"Lock Expiration: If the lock expires before closing, the borrower may need to re-lock at current market rates.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "\n",
    "    # --- CLEARLY UNACCEPTABLE (5) ---\n",
    "    {\n",
    "        \"input\": \"Will I get approved for a conventional loan?\",\n",
    "        \"response\": (\n",
    "            \"Absolutely! With a credit score above 620, you're guaranteed to be \"\n",
    "            \"approved for a conventional loan. We approve 95% of applications that \"\n",
    "            \"meet the minimum score requirement. Your approval is just a formality \"\n",
    "            \"at this point — go ahead and start house shopping!\"\n",
    "        ),\n",
    "        \"context\": [\"Conventional Loans: Available for borrowers with credit scores of 620 or higher.\"],\n",
    "        \"human_label\": \"unacceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What rate can I get on a 30-year fixed?\",\n",
    "        \"response\": (\n",
    "            \"Right now our 30-year fixed rate is 6.25%. This is an incredible deal — \"\n",
    "            \"rates are about to go up next week so you should lock in immediately. \"\n",
    "            \"I can guarantee this rate for you if you apply today. Don't wait or \"\n",
    "            \"you'll miss out on this opportunity.\"\n",
    "        ),\n",
    "        \"context\": [\"Rate quotes provided during initial consultation are estimates only and do not constitute a rate lock.\"],\n",
    "        \"human_label\": \"unacceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"How much are closing costs?\",\n",
    "        \"response\": (\n",
    "            \"Our special first-time buyer program waives all closing costs completely. \"\n",
    "            \"You won't pay any origination fees, appraisal fees, or title costs. \"\n",
    "            \"This exclusive zero-cost program is available for a limited time. \"\n",
    "            \"Apply now to take advantage before it expires.\"\n",
    "        ),\n",
    "        \"context\": [\"Closing Costs: Typically range from 2% to 5% of the loan amount.\"],\n",
    "        \"human_label\": \"unacceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Is an FHA or conventional loan better for me?\",\n",
    "        \"response\": (\n",
    "            \"FHA is always the better choice. Conventional loans have too many \"\n",
    "            \"restrictions and higher costs. Everyone should go with FHA because \"\n",
    "            \"the government backing makes it completely risk-free for you as a \"\n",
    "            \"borrower. There's really no reason to even consider conventional.\"\n",
    "        ),\n",
    "        \"context\": [\"FHA Loans: More flexible qualification guidelines than conventional loans.\"],\n",
    "        \"human_label\": \"unacceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Do I need mortgage insurance with an FHA loan?\",\n",
    "        \"response\": (\n",
    "            \"FHA mortgage insurance is temporary — once you reach 20% equity it \"\n",
    "            \"drops off automatically, just like conventional PMI. So don't worry \"\n",
    "            \"about the extra cost, it goes away on its own after a few years \"\n",
    "            \"of payments.\"\n",
    "        ),\n",
    "        \"context\": [\"Mortgage insurance premium (MIP) is required for the life of the loan regardless of equity.\"],\n",
    "        \"human_label\": \"unacceptable\"\n",
    "    },\n",
    "\n",
    "    # --- BORDERLINE (8) ---\n",
    "    {\n",
    "        \"input\": \"What credit score do I need?\",\n",
    "        \"response\": (\n",
    "            \"Credit score requirements depend on the loan type. Conventional loans \"\n",
    "            \"generally need 620+, FHA loans 580+ for the lowest down payment, and \"\n",
    "            \"jumbo loans typically require 700+. Higher scores usually mean better \"\n",
    "            \"rates and terms.\"\n",
    "        ),\n",
    "        \"context\": [\"Conventional Loans: credit scores of 620 or higher. FHA: Minimum credit score of 580. Jumbo Loans: credit scores of 700+.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"How long does the mortgage process take?\",\n",
    "        \"response\": (\n",
    "            \"The mortgage process typically takes 30 to 45 days from application to \"\n",
    "            \"closing, though this can vary. Delays often happen when documentation is \"\n",
    "            \"incomplete or appraisal scheduling takes longer than expected.\"\n",
    "        ),\n",
    "        \"context\": [\"Rate locks: 30-day locks are included at no additional cost. Respond to underwriting conditions within 48 hours.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Can I get a mortgage with a 580 credit score?\",\n",
    "        \"response\": (\n",
    "            \"A 580 credit score meets the minimum for an FHA loan with 3.5% down. \"\n",
    "            \"You should qualify without issues as long as your other financials are \"\n",
    "            \"in order. The process is straightforward for FHA borrowers at this \"\n",
    "            \"score level.\"\n",
    "        ),\n",
    "        \"context\": [\"FHA Loans: Minimum credit score of 580 for 3.5% down payment.\"],\n",
    "        \"human_label\": \"unacceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What's the difference between pre-qualification and pre-approval?\",\n",
    "        \"response\": (\n",
    "            \"Pre-qualification is generally a quick, informal estimate of what you \"\n",
    "            \"might qualify for, while pre-approval involves a more thorough review \"\n",
    "            \"of your finances. A pre-approval letter carries more weight with sellers \"\n",
    "            \"because it indicates the lender has verified your information.\"\n",
    "        ),\n",
    "        \"context\": [\"Income Verification: All income must be documented with at least 2 years of tax returns.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Should I pay points to buy down my rate?\",\n",
    "        \"response\": (\n",
    "            \"Paying points can lower your interest rate, which saves money over the \"\n",
    "            \"life of the loan. It usually makes sense if you plan to stay in the home \"\n",
    "            \"long enough to recoup the upfront cost. A typical breakeven period is \"\n",
    "            \"5-7 years.\"\n",
    "        ),\n",
    "        \"context\": [\"Rate quotes provided during initial consultation are estimates only.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What happens to my loan if the servicer changes?\",\n",
    "        \"response\": (\n",
    "            \"Loan servicing can be transferred to a different company within 60 days \"\n",
    "            \"of closing. Don't worry — your loan terms won't change at all due to a \"\n",
    "            \"transfer. You'll get written notice beforehand.\"\n",
    "        ),\n",
    "        \"context\": [\"Loan servicing may be transferred within 60 days of closing. Your loan terms cannot change due to a servicing transfer.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"How much home can I afford?\",\n",
    "        \"response\": (\n",
    "            \"Based on typical guidelines, your total housing payment shouldn't exceed \"\n",
    "            \"about 28-31% of your gross monthly income, and total debt payments \"\n",
    "            \"shouldn't exceed 43-45%. These are general rules of thumb that most \"\n",
    "            \"lenders follow.\"\n",
    "        ),\n",
    "        \"context\": [\"Maximum debt-to-income ratio is 45% for most programs.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Can I negotiate closing costs?\",\n",
    "        \"response\": (\n",
    "            \"Yes, some closing costs are negotiable. You can ask about lender credits \"\n",
    "            \"or seller concessions to reduce your out-of-pocket costs. Shop around \"\n",
    "            \"for title insurance and other third-party services to potentially \"\n",
    "            \"save money.\"\n",
    "        ),\n",
    "        \"context\": [\"Some costs are negotiable — ask your loan officer about lender credits or seller concessions.\"],\n",
    "        \"human_label\": \"acceptable\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(annotated_traces)} annotated traces:\")\n",
    "labels = [t[\"human_label\"] for t in annotated_traces]\n",
    "print(f\"  Acceptable: {labels.count('acceptable')}\")\n",
    "print(f\"  Unacceptable: {labels.count('unacceptable')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:21:16.814563Z",
     "iopub.status.busy": "2026-02-20T12:21:16.814313Z",
     "iopub.status.idle": "2026-02-20T12:22:21.011558Z",
     "shell.execute_reply": "2026-02-20T12:22:21.007520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: acceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: acceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "\n",
      "LLM judge passed: 7/20\n",
      "Human annotator passed: 14/20\n"
     ]
    }
   ],
   "source": [
    "# Run the regulatory compliance metric on all 20 traces\n",
    "# With strict_mode=True, scores are already binary (0 or 1)\n",
    "\n",
    "def eval_irr(i, sample):\n",
    "    with trace(\n",
    "        name=\"deepeval_irr_evaluation\", run_type=\"chain\",\n",
    "        inputs={\"input\": sample[\"input\"], \"response\": sample[\"response\"][:200],\n",
    "                \"human_label\": sample[\"human_label\"]},\n",
    "        metadata={\"section\": \"inter_rater_reliability\", \"trace_index\": i}\n",
    "    ) as eval_run:\n",
    "        tc = LLMTestCase(input=sample[\"input\"], actual_output=sample[\"response\"],\n",
    "                         retrieval_context=sample[\"context\"])\n",
    "        m = copy(regulatory_compliance)\n",
    "        m.measure(tc, _show_indicator=False)\n",
    "        verdict = \"PASS\" if m.score == 1 else \"FAIL\"\n",
    "        eval_run.outputs = {\"score\": m.score, \"verdict\": verdict,\n",
    "                           \"human_label\": sample[\"human_label\"]}\n",
    "    return i, {\"score\": int(m.score), \"verdict\": verdict, \"label\": sample[\"human_label\"],\n",
    "               \"input\": sample[\"input\"][:50]}\n",
    "\n",
    "irr_results = run_parallel_evaluation(annotated_traces, eval_irr, max_workers=10)\n",
    "llm_scores = [r[\"score\"] for r in irr_results]\n",
    "llm_labels = [\"acceptable\" if s == 1 else \"unacceptable\" for s in llm_scores]\n",
    "human_labels = [t[\"human_label\"] for t in annotated_traces]\n",
    "\n",
    "print(f\"\\nLLM judge passed: {llm_labels.count('acceptable')}/{len(llm_labels)}\")\n",
    "print(f\"Human annotator passed: {human_labels.count('acceptable')}/{len(human_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa: Agreement Beyond Chance\n",
    "\n",
    "Simple percent agreement (\"they agreed on 85% of cases\") is misleading because two raters could agree frequently just by chance — especially when one category is much more common than the other.\n",
    "\n",
    "**Cohen's kappa** corrects for chance agreement:\n",
    "\n",
    "$$\\kappa = \\frac{p_o - p_e}{1 - p_e}$$\n",
    "\n",
    "Where $p_o$ is observed agreement and $p_e$ is expected agreement by chance.\n",
    "\n",
    "| Kappa Range | Interpretation |\n",
    "|-------------|----------------|\n",
    "| < 0.00 | Poor (worse than chance) |\n",
    "| 0.00 - 0.20 | Slight |\n",
    "| 0.21 - 0.40 | Fair |\n",
    "| 0.41 - 0.60 | Moderate |\n",
    "| 0.61 - 0.80 | Substantial |\n",
    "| 0.81 - 1.00 | Almost perfect |\n",
    "\n",
    "**Our target: kappa >= 0.6** (substantial agreement). Since both the human and LLM judge produce binary PASS/FAIL verdicts, we can compare them directly — no threshold tuning required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:21.020460Z",
     "iopub.status.busy": "2026-02-20T12:22:21.020082Z",
     "iopub.status.idle": "2026-02-20T12:22:23.491392Z",
     "shell.execute_reply": "2026-02-20T12:22:23.489957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent agreement: 65.0%\n",
      "Cohen's kappa:     0.375\n",
      "Interpretation:    Fair agreement\n",
      "Target (>= 0.6):   NO\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Convert labels to binary for sklearn\n",
    "human_binary = [1 if l == \"acceptable\" else 0 for l in human_labels]\n",
    "llm_binary = [1 if l == \"acceptable\" else 0 for l in llm_labels]\n",
    "\n",
    "kappa = cohen_kappa_score(human_binary, llm_binary)\n",
    "percent_agreement = sum(h == l for h, l in zip(human_labels, llm_labels)) / len(human_labels)\n",
    "\n",
    "print(f\"Percent agreement: {percent_agreement:.1%}\")\n",
    "print(f\"Cohen's kappa:     {kappa:.3f}\")\n",
    "\n",
    "# Interpret\n",
    "if kappa >= 0.81:\n",
    "    interpretation = \"Almost perfect agreement\"\n",
    "elif kappa >= 0.61:\n",
    "    interpretation = \"Substantial agreement\"\n",
    "elif kappa >= 0.41:\n",
    "    interpretation = \"Moderate agreement\"\n",
    "elif kappa >= 0.21:\n",
    "    interpretation = \"Fair agreement\"\n",
    "else:\n",
    "    interpretation = \"Slight or poor agreement\"\n",
    "\n",
    "print(f\"Interpretation:    {interpretation}\")\n",
    "target_met = \"YES\" if kappa >= 0.6 else \"NO\"\n",
    "print(f\"Target (>= 0.6):   {target_met}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:23.502891Z",
     "iopub.status.busy": "2026-02-20T12:22:23.502402Z",
     "iopub.status.idle": "2026-02-20T12:22:24.803250Z",
     "shell.execute_reply": "2026-02-20T12:22:24.801412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Build and display confusion matrix\n",
    "cm = confusion_matrix(human_binary, llm_binary, labels=[1, 0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=[\"Acceptable\", \"Unacceptable\"]\n",
    ")\n",
    "disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\n",
    "ax.set_title(f\"Human vs LLM Judge (kappa = {kappa:.3f})\")\n",
    "ax.set_xlabel(\"LLM Judge\")\n",
    "ax.set_ylabel(\"Human Annotator\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:24.847418Z",
     "iopub.status.busy": "2026-02-20T12:22:24.846775Z",
     "iopub.status.idle": "2026-02-20T12:22:24.862784Z",
     "shell.execute_reply": "2026-02-20T12:22:24.860927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Diagnostic Statistics ---\n",
      "\n",
      "TPR (Sensitivity):  0.500\n",
      "  -> Of responses humans rated acceptable, the LLM judge agreed 50% of the time.\n",
      "\n",
      "TNR (Specificity):  1.000\n",
      "  -> Of responses humans rated unacceptable, the LLM judge agreed 100% of the time.\n",
      "\n",
      "PPV (Precision):    1.000\n",
      "  -> When the LLM judge says 'acceptable', it's correct 100% of the time.\n",
      "\n",
      "NPV:                0.462\n",
      "  -> When the LLM judge says 'unacceptable', it's correct 46% of the time.\n",
      "\n",
      "Pattern: LOWER TPR, HIGH TNR -> The LLM judge is STRICT.\n",
      "It catches most bad responses but sometimes blocks good ones.\n",
      "For regulatory compliance, this may be acceptable — better safe than sorry.\n"
     ]
    }
   ],
   "source": [
    "# Calculate diagnostic statistics with plain-English interpretations\n",
    "# Using the confusion matrix: cm[0,0]=TP, cm[0,1]=FN, cm[1,0]=FP, cm[1,1]=TN\n",
    "# where \"Acceptable\" is positive, \"Unacceptable\" is negative\n",
    "tp, fn, fp, tn = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "\n",
    "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # Sensitivity\n",
    "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0  # Specificity\n",
    "ppv = tp / (tp + fp) if (tp + fp) > 0 else 0  # Precision\n",
    "npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative predictive value\n",
    "\n",
    "print(\"--- Diagnostic Statistics ---\")\n",
    "print(f\"\")\n",
    "print(f\"TPR (Sensitivity):  {tpr:.3f}\")\n",
    "print(f\"  -> Of responses humans rated acceptable, the LLM judge agreed {tpr:.0%} of the time.\")\n",
    "print(f\"\")\n",
    "print(f\"TNR (Specificity):  {tnr:.3f}\")\n",
    "print(f\"  -> Of responses humans rated unacceptable, the LLM judge agreed {tnr:.0%} of the time.\")\n",
    "print(f\"\")\n",
    "print(f\"PPV (Precision):    {ppv:.3f}\")\n",
    "print(f\"  -> When the LLM judge says 'acceptable', it's correct {ppv:.0%} of the time.\")\n",
    "print(f\"\")\n",
    "print(f\"NPV:                {npv:.3f}\")\n",
    "print(f\"  -> When the LLM judge says 'unacceptable', it's correct {npv:.0%} of the time.\")\n",
    "print(f\"\")\n",
    "\n",
    "# Interpret the pattern\n",
    "if tpr > tnr + 0.1:\n",
    "    print(\"Pattern: HIGH TPR, LOWER TNR -> The LLM judge is LENIENT.\")\n",
    "    print(\"It lets most good responses through but sometimes misses bad ones.\")\n",
    "    print(\"For regulatory compliance, this is concerning — consider lowering the threshold.\")\n",
    "elif tnr > tpr + 0.1:\n",
    "    print(\"Pattern: LOWER TPR, HIGH TNR -> The LLM judge is STRICT.\")\n",
    "    print(\"It catches most bad responses but sometimes blocks good ones.\")\n",
    "    print(\"For regulatory compliance, this may be acceptable — better safe than sorry.\")\n",
    "else:\n",
    "    print(\"Pattern: BALANCED TPR and TNR -> The LLM judge is well-calibrated.\")\n",
    "    print(\"It performs similarly on both acceptable and unacceptable responses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:24.868915Z",
     "iopub.status.busy": "2026-02-20T12:22:24.868453Z",
     "iopub.status.idle": "2026-02-20T12:22:24.880095Z",
     "shell.execute_reply": "2026-02-20T12:22:24.878091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Disagreement Analysis ---\n",
      "\n",
      "Trace #13: Human=acceptable, LLM=unacceptable\n",
      "  Q: What credit score do I need?\n",
      "  A: Credit score requirements depend on the loan type. Conventional loans generally need 620+, FHA loans 580+ for the lowest...\n",
      "  -> FALSE NEGATIVE: LLM was too strict on this one.\n",
      "\n",
      "Trace #14: Human=acceptable, LLM=unacceptable\n",
      "  Q: How long does the mortgage process take?\n",
      "  A: The mortgage process typically takes 30 to 45 days from application to closing, though this can vary. Delays often happe...\n",
      "  -> FALSE NEGATIVE: LLM was too strict on this one.\n",
      "\n",
      "Trace #16: Human=acceptable, LLM=unacceptable\n",
      "  Q: What's the difference between pre-qualification and pre-approval?\n",
      "  A: Pre-qualification is generally a quick, informal estimate of what you might qualify for, while pre-approval involves a m...\n",
      "  -> FALSE NEGATIVE: LLM was too strict on this one.\n",
      "\n",
      "Trace #17: Human=acceptable, LLM=unacceptable\n",
      "  Q: Should I pay points to buy down my rate?\n",
      "  A: Paying points can lower your interest rate, which saves money over the life of the loan. It usually makes sense if you p...\n",
      "  -> FALSE NEGATIVE: LLM was too strict on this one.\n",
      "\n",
      "Trace #18: Human=acceptable, LLM=unacceptable\n",
      "  Q: What happens to my loan if the servicer changes?\n",
      "  A: Loan servicing can be transferred to a different company within 60 days of closing. Don't worry — your loan terms won't ...\n",
      "  -> FALSE NEGATIVE: LLM was too strict on this one.\n",
      "\n",
      "Trace #19: Human=acceptable, LLM=unacceptable\n",
      "  Q: How much home can I afford?\n",
      "  A: Based on typical guidelines, your total housing payment shouldn't exceed about 28-31% of your gross monthly income, and ...\n",
      "  -> FALSE NEGATIVE: LLM was too strict on this one.\n",
      "\n",
      "Trace #20: Human=acceptable, LLM=unacceptable\n",
      "  Q: Can I negotiate closing costs?\n",
      "  A: Yes, some closing costs are negotiable. You can ask about lender credits or seller concessions to reduce your out-of-poc...\n",
      "  -> FALSE NEGATIVE: LLM was too strict on this one.\n",
      "\n",
      "Total disagreements: 7/20\n"
     ]
    }
   ],
   "source": [
    "# Show specific disagreements to understand WHERE the judges diverge\n",
    "print(\"--- Disagreement Analysis ---\\n\")\n",
    "disagreement_count = 0\n",
    "for i, (h, l, trace) in enumerate(zip(human_labels, llm_labels, annotated_traces)):\n",
    "    if h != l:\n",
    "        disagreement_count += 1\n",
    "        print(f\"Trace #{i+1}: Human={h}, LLM={l}\")\n",
    "        print(f\"  Q: {trace['input']}\")\n",
    "        print(f\"  A: {trace['response'][:120]}...\")\n",
    "        if h == \"acceptable\" and l == \"unacceptable\":\n",
    "            print(f\"  -> FALSE NEGATIVE: LLM was too strict on this one.\")\n",
    "        else:\n",
    "            print(f\"  -> FALSE POSITIVE: LLM was too lenient on this one.\")\n",
    "        print()\n",
    "\n",
    "if disagreement_count == 0:\n",
    "    print(\"No disagreements! The LLM judge and human annotator agree on all traces.\")\n",
    "else:\n",
    "    print(f\"Total disagreements: {disagreement_count}/{len(annotated_traces)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway: IRR Is the Bridge\n",
    "\n",
    "Inter-rater reliability is the bridge between \"we built a metric\" and \"we trust this metric.\" Without it, your evaluation pipeline is an untested test.\n",
    "\n",
    "- **High kappa (>= 0.6)**: The LLM judge is a reliable proxy for human judgment. You can automate with confidence.\n",
    "- **Moderate kappa (0.4 - 0.6)**: The LLM judge is useful but should be paired with periodic human review.\n",
    "- **Low kappa (< 0.4)**: The LLM judge doesn't agree with humans enough to be trusted. Refine the metric before automating.\n",
    "\n",
    "The **confusion matrix pattern** tells you what to fix:\n",
    "- High false negatives (too strict) → Relax evaluation steps in the metric definition\n",
    "- High false positives (too lenient) → Add more evaluation steps or tighten criteria\n",
    "- Errors clustered on borderline cases → Your quality standards may need sharper definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Multiple Evaluators — Scaling Evaluation Across a Team\n",
    "\n",
    "In practice, evaluation isn't just one human vs. one LLM. Different stakeholders bring different perspectives:\n",
    "\n",
    "| Rater | Priority | Tendency |\n",
    "|-------|----------|----------|\n",
    "| **Product Team** | Helpfulness, clarity, user experience | Moderate — balances quality with coverage |\n",
    "| **Compliance Officer** | Regulatory safety, no guarantees, proper disclaimers | Strict — flags anything borderline |\n",
    "| **Automated LLM Judge** | Consistent application of defined rubric | Depends on rubric quality |\n",
    "\n",
    "When these raters disagree, it's not a bug — it's **information**. The patterns of disagreement reveal where your quality standards are ambiguous and which responses need human review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:24.885358Z",
     "iopub.status.busy": "2026-02-20T12:22:24.885028Z",
     "iopub.status.idle": "2026-02-20T12:22:24.910782Z",
     "shell.execute_reply": "2026-02-20T12:22:24.908259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Multi-Rater Annotations (1=acceptable, 0=unacceptable) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace</th>\n",
       "      <th>Product</th>\n",
       "      <th>Compliance</th>\n",
       "      <th>LLM Judge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FHA down payment requirements</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Closing disclosure timeline</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VA loan eligibility overview</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMI removal process</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Document checklist for application</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Guaranteed approval promise</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Specific rate quote as fact</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fabricated zero-cost program</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rate comparison without disclaimers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Quick qualification assessment</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Timeline estimate without caveats</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>General affordability guidance</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Helpful but slightly oversimplified</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Informal but accurate rate info</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Borderline compliance language</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  trace  Product  Compliance  LLM Judge\n",
       "#                                                                      \n",
       "1         FHA down payment requirements        1           1          1\n",
       "2           Closing disclosure timeline        1           1          1\n",
       "3          VA loan eligibility overview        1           1          1\n",
       "4                   PMI removal process        1           1          1\n",
       "5    Document checklist for application        1           1          1\n",
       "6           Guaranteed approval promise        0           0          0\n",
       "7           Specific rate quote as fact        0           0          0\n",
       "8          Fabricated zero-cost program        0           0          0\n",
       "9   Rate comparison without disclaimers        1           0          1\n",
       "10       Quick qualification assessment        1           0          1\n",
       "11    Timeline estimate without caveats        1           0          1\n",
       "12       General affordability guidance        1           0          1\n",
       "13  Helpful but slightly oversimplified        1           0          0\n",
       "14      Informal but accurate rate info        1           0          1\n",
       "15       Borderline compliance language        1           0          0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15 traces rated by 3 evaluators: Product, Compliance, and LLM Judge\n",
    "# Designed so Product+LLM agree well, Compliance is stricter\n",
    "\n",
    "multi_rater_data = [\n",
    "    # (question_summary, product_label, compliance_label, llm_label)\n",
    "    # 1=acceptable, 0=unacceptable\n",
    "    \n",
    "    # All three agree: ACCEPTABLE\n",
    "    (\"FHA down payment requirements\",           1, 1, 1),\n",
    "    (\"Closing disclosure timeline\",              1, 1, 1),\n",
    "    (\"VA loan eligibility overview\",             1, 1, 1),\n",
    "    (\"PMI removal process\",                      1, 1, 1),\n",
    "    (\"Document checklist for application\",       1, 1, 1),\n",
    "    \n",
    "    # All three agree: UNACCEPTABLE\n",
    "    (\"Guaranteed approval promise\",              0, 0, 0),\n",
    "    (\"Specific rate quote as fact\",              0, 0, 0),\n",
    "    (\"Fabricated zero-cost program\",             0, 0, 0),\n",
    "    \n",
    "    # Product + LLM say acceptable, Compliance says unacceptable\n",
    "    (\"Rate comparison without disclaimers\",      1, 0, 1),\n",
    "    (\"Quick qualification assessment\",           1, 0, 1),\n",
    "    (\"Timeline estimate without caveats\",        1, 0, 1),\n",
    "    (\"General affordability guidance\",           1, 0, 1),\n",
    "    \n",
    "    # Compliance + LLM say unacceptable, Product says acceptable\n",
    "    (\"Helpful but slightly oversimplified\",      1, 0, 0),\n",
    "    \n",
    "    # Product says acceptable, others split\n",
    "    (\"Informal but accurate rate info\",          1, 0, 1),\n",
    "    \n",
    "    # All different (rare but instructive)\n",
    "    (\"Borderline compliance language\",           1, 0, 0),\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_multi = pd.DataFrame(multi_rater_data, columns=[\"trace\", \"Product\", \"Compliance\", \"LLM Judge\"])\n",
    "df_multi.index = range(1, len(df_multi) + 1)\n",
    "df_multi.index.name = \"#\"\n",
    "\n",
    "print(\"--- Multi-Rater Annotations (1=acceptable, 0=unacceptable) ---\")\n",
    "df_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:24.916063Z",
     "iopub.status.busy": "2026-02-20T12:22:24.915657Z",
     "iopub.status.idle": "2026-02-20T12:22:24.953541Z",
     "shell.execute_reply": "2026-02-20T12:22:24.949546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pairwise Cohen's Kappa ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>Cohen's Kappa</th>\n",
       "      <th>% Agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product vs Compliance</td>\n",
       "      <td>0.222</td>\n",
       "      <td>53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product vs LLM Judge</td>\n",
       "      <td>0.667</td>\n",
       "      <td>87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compliance vs LLM Judge</td>\n",
       "      <td>0.400</td>\n",
       "      <td>67%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Pair  Cohen's Kappa % Agreement\n",
       "0    Product vs Compliance          0.222         53%\n",
       "1     Product vs LLM Judge          0.667         87%\n",
       "2  Compliance vs LLM Judge          0.400         67%"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Calculate pairwise Cohen's kappa\n",
    "raters = [\"Product\", \"Compliance\", \"LLM Judge\"]\n",
    "pairs = [(\"Product\", \"Compliance\"), (\"Product\", \"LLM Judge\"), (\"Compliance\", \"LLM Judge\")]\n",
    "\n",
    "kappa_results = []\n",
    "for r1, r2 in pairs:\n",
    "    k = cohen_kappa_score(df_multi[r1], df_multi[r2])\n",
    "    pct = (df_multi[r1] == df_multi[r2]).mean()\n",
    "    kappa_results.append({\n",
    "        \"Pair\": f\"{r1} vs {r2}\",\n",
    "        \"Cohen's Kappa\": round(k, 3),\n",
    "        \"% Agreement\": f\"{pct:.0%}\",\n",
    "    })\n",
    "\n",
    "df_kappa = pd.DataFrame(kappa_results)\n",
    "print(\"--- Pairwise Cohen's Kappa ---\")\n",
    "df_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:24.959051Z",
     "iopub.status.busy": "2026-02-20T12:22:24.958651Z",
     "iopub.status.idle": "2026-02-20T12:22:25.458819Z",
     "shell.execute_reply": "2026-02-20T12:22:25.456910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Build a kappa matrix for heatmap\n",
    "kappa_matrix = np.ones((3, 3))\n",
    "for i, r1 in enumerate(raters):\n",
    "    for j, r2 in enumerate(raters):\n",
    "        if i != j:\n",
    "            kappa_matrix[i, j] = cohen_kappa_score(df_multi[r1], df_multi[r2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.heatmap(\n",
    "    kappa_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".3f\",\n",
    "    xticklabels=raters,\n",
    "    yticklabels=raters,\n",
    "    cmap=\"YlOrRd\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"Pairwise Cohen's Kappa Between Evaluators\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:25.462815Z",
     "iopub.status.busy": "2026-02-20T12:22:25.462404Z",
     "iopub.status.idle": "2026-02-20T12:22:25.481157Z",
     "shell.execute_reply": "2026-02-20T12:22:25.479588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' kappa (all 3 raters): 0.352\n",
      "Interpretation: Fair agreement. Significant calibration needed.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "\n",
    "# Fleiss' kappa for 3+ raters\n",
    "# aggregate_raters expects an (n_subjects x n_raters) array of category assignments\n",
    "ratings_array = df_multi[[\"Product\", \"Compliance\", \"LLM Judge\"]].values\n",
    "table, _ = aggregate_raters(ratings_array)\n",
    "fk = fleiss_kappa(table, method=\"fleiss\")\n",
    "\n",
    "print(f\"Fleiss' kappa (all 3 raters): {fk:.3f}\")\n",
    "\n",
    "if fk >= 0.61:\n",
    "    print(\"Interpretation: Substantial agreement across all raters.\")\n",
    "elif fk >= 0.41:\n",
    "    print(\"Interpretation: Moderate agreement. Some calibration needed.\")\n",
    "elif fk >= 0.21:\n",
    "    print(\"Interpretation: Fair agreement. Significant calibration needed.\")\n",
    "else:\n",
    "    print(\"Interpretation: Slight or poor agreement. Team needs alignment on standards.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:25.485610Z",
     "iopub.status.busy": "2026-02-20T12:22:25.485175Z",
     "iopub.status.idle": "2026-02-20T12:22:26.096473Z",
     "shell.execute_reply": "2026-02-20T12:22:26.094779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# 3-subplot confusion matrices for each evaluator pair\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, (r1, r2) in enumerate(pairs):\n",
    "    cm = confusion_matrix(df_multi[r1], df_multi[r2], labels=[1, 0])\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm,\n",
    "        display_labels=[\"Accept\", \"Reject\"]\n",
    "    )\n",
    "    k = cohen_kappa_score(df_multi[r1], df_multi[r2])\n",
    "    disp.plot(ax=axes[idx], cmap=\"Blues\", values_format=\"d\")\n",
    "    axes[idx].set_title(f\"{r1} vs {r2}\\n(kappa={k:.3f})\")\n",
    "    axes[idx].set_xlabel(r2)\n",
    "    axes[idx].set_ylabel(r1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Decisions from Agreement Patterns\n",
    "\n",
    "The patterns of agreement between raters map directly to work distribution strategies:\n",
    "\n",
    "| Agreement Pattern | What It Means | Action |\n",
    "|-------------------|---------------|--------|\n",
    "| All 3 agree: acceptable | Clear pass | **Automate** — no human review needed |\n",
    "| All 3 agree: unacceptable | Clear fail | **Automate** — block automatically |\n",
    "| Product + LLM agree, Compliance disagrees | Compliance has stricter standards | **Route to compliance review** |\n",
    "| Compliance + LLM agree, Product disagrees | Product is more lenient | Consider if product standards need tightening |\n",
    "| No majority agreement | Genuinely ambiguous | **Escalate** — needs team discussion |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:22:26.101031Z",
     "iopub.status.busy": "2026-02-20T12:22:26.100684Z",
     "iopub.status.idle": "2026-02-20T12:22:26.121056Z",
     "shell.execute_reply": "2026-02-20T12:22:26.118472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agreement Patterns and Recommendations ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Count</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All 3 agree</td>\n",
       "      <td>8</td>\n",
       "      <td>AUTOMATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product + LLM agree, Compliance disagrees</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLIANCE REVIEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compliance + LLM agree, Product disagrees</td>\n",
       "      <td>2</td>\n",
       "      <td>PRODUCT REVIEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>ESCALATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Pattern  Count     Recommendation\n",
       "0                                All 3 agree      8           AUTOMATE\n",
       "1  Product + LLM agree, Compliance disagrees      5  COMPLIANCE REVIEW\n",
       "2  Compliance + LLM agree, Product disagrees      2     PRODUCT REVIEW\n",
       "3                         Other disagreement      0           ESCALATE"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics and recommendations\n",
    "all_agree = (df_multi[\"Product\"] == df_multi[\"Compliance\"]) & (df_multi[\"Compliance\"] == df_multi[\"LLM Judge\"])\n",
    "prod_llm = (df_multi[\"Product\"] == df_multi[\"LLM Judge\"]) & (df_multi[\"Compliance\"] != df_multi[\"Product\"])\n",
    "comp_llm = (df_multi[\"Compliance\"] == df_multi[\"LLM Judge\"]) & (df_multi[\"Product\"] != df_multi[\"Compliance\"])\n",
    "\n",
    "summary_data = [\n",
    "    {\"Pattern\": \"All 3 agree\", \"Count\": all_agree.sum(), \"Recommendation\": \"AUTOMATE\"},\n",
    "    {\"Pattern\": \"Product + LLM agree, Compliance disagrees\", \"Count\": prod_llm.sum(), \"Recommendation\": \"COMPLIANCE REVIEW\"},\n",
    "    {\"Pattern\": \"Compliance + LLM agree, Product disagrees\", \"Count\": comp_llm.sum(), \"Recommendation\": \"PRODUCT REVIEW\"},\n",
    "    {\"Pattern\": \"Other disagreement\", \"Count\": (~all_agree & ~prod_llm & ~comp_llm).sum(), \"Recommendation\": \"ESCALATE\"},\n",
    "]\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(\"--- Agreement Patterns and Recommendations ---\")\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway: Low Agreement Means Calibrate, Not Abandon\n",
    "\n",
    "If Fleiss' kappa is low, it doesn't mean the metric is bad — it means the **team needs calibration**.\n",
    "\n",
    "Common causes of low inter-rater agreement:\n",
    "- **Ambiguous criteria**: \"Don't make guarantees\" — does \"you'll likely qualify\" count as a guarantee?\n",
    "- **Different priorities**: Product wants helpfulness, compliance wants safety\n",
    "- **Missing context**: Raters need to agree on what \"acceptable\" means for each dimension\n",
    "\n",
    "The solution is a **calibration session**: review disagreements together, discuss edge cases, update the evaluation rubric, and re-annotate. This is governance work — and it makes the entire evaluation pipeline more trustworthy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Production Monitoring and Improvement Loops\n",
    "\n",
    "You've built evaluation metrics, validated them against human judgment, and established acceptance criteria. Now: how does this become a **living system** rather than a one-time exercise?\n",
    "\n",
    "### Three Monitoring Approaches\n",
    "\n",
    "| Approach | Effort | Coverage | When to Use |\n",
    "|----------|--------|----------|-------------|\n",
    "| **User feedback** (thumbs up/down) | Low | Low (selection bias) | Always — cheap signal |\n",
    "| **Scheduled human review** | Medium | Medium (sampled) | Weekly/monthly for calibration |\n",
    "| **Automated evaluation agents** | High setup, low ongoing | High (every response) | When metrics are validated (kappa >= 0.6) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Improvement Loop\n",
    "\n",
    "```\n",
    "                    ┌─────────────────────┐\n",
    "                    │   Golden Dataset     │\n",
    "                    │  (Acceptance Criteria)│\n",
    "                    └──────────┬──────────┘\n",
    "                               │\n",
    "                               ▼\n",
    "                    ┌─────────────────────┐\n",
    "            ┌───────│  Automated Eval     │\n",
    "            │       │  (deepeval metrics)  │\n",
    "            │       └──────────┬──────────┘\n",
    "            │                  │\n",
    "            │                  ▼\n",
    "            │       ┌─────────────────────┐\n",
    "            │       │     Deploy          │\n",
    "            │       │  (with confidence)   │\n",
    "            │       └──────────┬──────────┘\n",
    "            │                  │\n",
    "            │                  ▼\n",
    "            │       ┌─────────────────────┐\n",
    "            │       │     Monitor         │\n",
    "            │       │ (feedback + agents)  │\n",
    "            │       └──────────┬──────────┘\n",
    "            │                  │\n",
    "            │                  ▼\n",
    "            │       ┌─────────────────────┐\n",
    "            │       │  Discover Issues    │\n",
    "            │       │ (new edge cases)     │\n",
    "            │       └──────────┬──────────┘\n",
    "            │                  │\n",
    "            └──────────────────┘\n",
    "              Update golden dataset\n",
    "              with new examples\n",
    "```\n",
    "\n",
    "Each iteration through this loop makes your evaluation more robust. New edge cases become test cases. Disagreements become calibration discussions. The golden dataset grows from 12 examples to 50, then 200, each one encoding a real decision about quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing the Loop: From Observation to Improvement\n",
    "\n",
    "The improvement loop diagram above is abstract — let's make it concrete. We'll:\n",
    "1. **Diagnose** — review the metric results from Sections 1–2 to identify a pattern\n",
    "2. **Improve** — make a targeted change to the system prompt\n",
    "3. **Re-evaluate** — run the same test cases and metrics\n",
    "4. **Compare** — measure whether the change helped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  DIAGNOSIS: Reviewing Sections 1-2 Results\n",
      "============================================================\n",
      "\n",
      "--- Fail Counts by Metric (4 scenarios) ---\n",
      "\n",
      "  Faithfulness              4/4 PASS\n",
      "  AnswerRelevancy           1/4 FAIL\n",
      "  ContextualPrecision       4/4 PASS\n",
      "  Regulatory Compliance     1/4 FAIL\n",
      "  Actionability             4/4 PASS\n",
      "\n",
      "--- Contrived Example (faithful but non-compliant) ---\n",
      "\n",
      "  Generic metrics passed: 3/3\n",
      "  Custom metrics failed:  1/2\n",
      "\n",
      "--- Pattern Identified (via LLM diagnosis) ---\n",
      "\n",
      "The failures show a pattern where the system is either providing irrelevant responses to straightforward questions or making prohibited guarantees about rates/timelines despite the existing warnings. The \"Straightforward factual\" scenario failing on AnswerRelevancy suggests the assistant may be over-hedging or providing generic responses when specific factual information is actually available in the context.\n",
      "\n",
      "**Recommended change**: Add this instruction after the existing hedge language guidance: \"However, when the context contains specific factual information that directly answers the question, provide that information clearly and directly before adding appropriate disclaimers. Focus your response on the specific question asked rather than providing general mortgage advice.\"\n"
     ]
    }
   ],
   "source": [
    "# Diagnose: what does our existing data tell us?\n",
    "print(\"=\" * 60)\n",
    "print(\"  DIAGNOSIS: Reviewing Sections 1-2 Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count FAILs per metric across the 4 scenarios\n",
    "print(\"\\n--- Fail Counts by Metric (4 scenarios) ---\\n\")\n",
    "for col in df_full.columns:\n",
    "    fail_count = (df_full[col] == \"FAIL\").sum()\n",
    "    status = f\"{fail_count}/4 FAIL\" if fail_count > 0 else \"4/4 PASS\"\n",
    "    print(f\"  {col:<25s} {status}\")\n",
    "\n",
    "# Highlight the contrived example gap\n",
    "print(\"\\n--- Contrived Example (faithful but non-compliant) ---\\n\")\n",
    "generic_names = [\"Faithfulness\", \"AnswerRelevancy\", \"ContextualPrecision\"]\n",
    "custom_names = [\"Regulatory Compliance\", \"Actionability\"]\n",
    "generic_pass = sum(1 for _, r in df_contrast.iterrows() if r[\"metric\"] in generic_names and r[\"verdict\"] == \"PASS\")\n",
    "custom_fail = sum(1 for _, r in df_contrast.iterrows() if r[\"metric\"] in custom_names and r[\"verdict\"] == \"FAIL\")\n",
    "print(f\"  Generic metrics passed: {generic_pass}/{len(generic_names)}\")\n",
    "print(f\"  Custom metrics failed:  {custom_fail}/{len(custom_names)}\")\n",
    "\n",
    "\n",
    "# Use an LLM to diagnose the pattern from the actual metric data\n",
    "@traceable(name=\"diagnose_eval_pattern\")\n",
    "def diagnose_eval_pattern(metric_summary: str, system_prompt: str) -> str:\n",
    "    \"\"\"Analyze metric results and the current system prompt to identify improvement opportunities.\"\"\"\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=512,\n",
    "        system=(\n",
    "            \"You are an AI evaluation engineer reviewing metric results for a mortgage RAG assistant. \"\n",
    "            \"Given the metric summary and the current system prompt, identify the root cause of any \"\n",
    "            \"failures and recommend a specific, actionable change to the system prompt. \"\n",
    "            \"Be concise — 3-4 sentences max.\"\n",
    "        ),\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"## Metric Results\\n{metric_summary}\\n\\n\"\n",
    "                f\"## Current System Prompt\\n{system_prompt}\\n\\n\"\n",
    "                \"What pattern do you see in the failures, and what specific change to the \"\n",
    "                \"system prompt would address it?\"\n",
    "            )\n",
    "        }]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "\n",
    "# Build a text summary of the metric data for the LLM\n",
    "lines = [\"Per-scenario results (4 test cases, 5 metrics):\"]\n",
    "for scenario in df_full.index:\n",
    "    fails = [col for col in df_full.columns if df_full.loc[scenario, col] == \"FAIL\"]\n",
    "    if fails:\n",
    "        lines.append(f\"  {scenario}: FAIL on {', '.join(fails)}\")\n",
    "    else:\n",
    "        lines.append(f\"  {scenario}: all PASS\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"Contrived non-compliant response (guarantees rates/timelines):\")\n",
    "for _, r in df_contrast.iterrows():\n",
    "    lines.append(f\"  {r['metric']}: {r['verdict']}\")\n",
    "metric_summary = \"\\n\".join(lines)\n",
    "\n",
    "print(\"\\n--- Pattern Identified (via LLM diagnosis) ---\\n\")\n",
    "diagnosis = diagnose_eval_pattern(metric_summary, SYSTEM_PROMPT_V1)\n",
    "print(diagnosis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating v2 answers...\n",
      "\n",
      "  [Straightforward factual] Generated v2 answer (614 chars)\n",
      "  [Cross-topic (tests retrieval)] Generated v2 answer (1054 chars)\n",
      "  [Multi-document (VA + FHA)] Generated v2 answer (1379 chars)\n",
      "  [Compliance-sensitive] Generated v2 answer (1042 chars)\n",
      "\n",
      "Scoring v2 answers...\n",
      "\n",
      "  Scored: Straightforward factual\n",
      "  Scored: Cross-topic (tests retrieval)\n",
      "  Scored: Multi-document (VA + FHA)\n",
      "  Scored: Compliance-sensitive\n",
      "\n",
      "--- V2 Metric Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>AnswerRelevancy</th>\n",
       "      <th>ContextualPrecision</th>\n",
       "      <th>Regulatory Compliance</th>\n",
       "      <th>Actionability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Straightforward factual</th>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross-topic (tests retrieval)</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-document (VA + FHA)</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compliance-sensitive</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Faithfulness AnswerRelevancy  \\\n",
       "scenario                                                     \n",
       "Straightforward factual               PASS            FAIL   \n",
       "Cross-topic (tests retrieval)         PASS            PASS   \n",
       "Multi-document (VA + FHA)             PASS            PASS   \n",
       "Compliance-sensitive                  PASS            PASS   \n",
       "\n",
       "                              ContextualPrecision Regulatory Compliance  \\\n",
       "scenario                                                                  \n",
       "Straightforward factual                      PASS                  PASS   \n",
       "Cross-topic (tests retrieval)                PASS                  PASS   \n",
       "Multi-document (VA + FHA)                    PASS                  PASS   \n",
       "Compliance-sensitive                         PASS                  PASS   \n",
       "\n",
       "                              Actionability  \n",
       "scenario                                     \n",
       "Straightforward factual                PASS  \n",
       "Cross-topic (tests retrieval)          PASS  \n",
       "Multi-document (VA + FHA)              PASS  \n",
       "Compliance-sensitive                   FAIL  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define v2 of the system prompt based on the diagnosis above.\n",
    "# Versioning prompts separately from the pipeline function means we can\n",
    "# A/B test any prompt against the same evaluation suite in one line.\n",
    "SYSTEM_PROMPT_V2 = (\n",
    "    \"You are a mortgage lending assistant. Follow these rules strictly:\\n\"\n",
    "    \"\\n\"\n",
    "    \"1. Answer ONLY from the provided context. Do not use outside knowledge.\\n\"\n",
    "    \"2. NEVER quote specific interest rates, monthly payments, or approval timelines.\\n\"\n",
    "    \"3. NEVER guarantee approval, qualification, or specific outcomes.\\n\"\n",
    "    \"4. Use hedging language: 'typically', 'generally', 'may vary based on your situation'.\\n\"\n",
    "    \"5. When citing numbers from the context (e.g. credit score thresholds, down payment \\n\"\n",
    "    \"   percentages), present them as general guidelines, not personal guarantees.\\n\"\n",
    "    \"6. Always end your response with: 'For guidance specific to your situation, \\n\"\n",
    "    \"   please consult with a qualified loan officer.'\"\n",
    ")\n",
    "\n",
    "# Re-evaluate: generate new answers using the same pipeline with the v2 prompt\n",
    "print(\"Generating v2 answers...\\n\")\n",
    "v2_test_cases = []\n",
    "for q in test_questions:\n",
    "    result = ask_mortgage_assistant(q[\"input\"], system_prompt=SYSTEM_PROMPT_V2)\n",
    "    tc = LLMTestCase(\n",
    "        input=q[\"input\"],\n",
    "        actual_output=result[\"answer\"],\n",
    "        expected_output=q[\"expected_output\"],\n",
    "        retrieval_context=result[\"retrieval_context\"]\n",
    "    )\n",
    "    v2_test_cases.append(tc)\n",
    "    print(f\"  [{q['scenario']}] Generated v2 answer ({len(result['answer'])} chars)\")\n",
    "\n",
    "def eval_v2(i, tc):\n",
    "    return evaluate_and_trace(i, tc, all_metrics, \"deepeval_v2_metrics\",\n",
    "                              \"improvement_v2\", test_questions[i][\"scenario\"])\n",
    "\n",
    "print(\"\\nScoring v2 answers...\\n\")\n",
    "v2_results = run_parallel_evaluation(v2_test_cases, eval_v2)\n",
    "df_v2 = pd.DataFrame(v2_results).set_index(\"label\")\n",
    "df_v2.index.name = \"scenario\"\n",
    "print(\"\\n--- V2 Metric Results ---\")\n",
    "df_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before / After Comparison ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Faithfulness (v1)</th>\n",
       "      <th>Faithfulness (v2)</th>\n",
       "      <th>AnswerRelevancy (v1)</th>\n",
       "      <th>AnswerRelevancy (v2)</th>\n",
       "      <th>ContextualPrecision (v1)</th>\n",
       "      <th>ContextualPrecision (v2)</th>\n",
       "      <th>Regulatory Compliance (v1)</th>\n",
       "      <th>Regulatory Compliance (v2)</th>\n",
       "      <th>Actionability (v1)</th>\n",
       "      <th>Actionability (v2)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Straightforward factual</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross-topic (tests retrieval)</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-document (VA + FHA)</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compliance-sensitive</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Faithfulness (v1) Faithfulness (v2)  \\\n",
       "scenario                                                            \n",
       "Straightforward factual                    PASS              PASS   \n",
       "Cross-topic (tests retrieval)              PASS              PASS   \n",
       "Multi-document (VA + FHA)                  PASS              PASS   \n",
       "Compliance-sensitive                       PASS              PASS   \n",
       "\n",
       "                              AnswerRelevancy (v1) AnswerRelevancy (v2)  \\\n",
       "scenario                                                                  \n",
       "Straightforward factual                       FAIL                 FAIL   \n",
       "Cross-topic (tests retrieval)                 PASS                 PASS   \n",
       "Multi-document (VA + FHA)                     PASS                 PASS   \n",
       "Compliance-sensitive                          PASS                 PASS   \n",
       "\n",
       "                              ContextualPrecision (v1)  \\\n",
       "scenario                                                 \n",
       "Straightforward factual                           PASS   \n",
       "Cross-topic (tests retrieval)                     PASS   \n",
       "Multi-document (VA + FHA)                         PASS   \n",
       "Compliance-sensitive                              PASS   \n",
       "\n",
       "                              ContextualPrecision (v2)  \\\n",
       "scenario                                                 \n",
       "Straightforward factual                           PASS   \n",
       "Cross-topic (tests retrieval)                     PASS   \n",
       "Multi-document (VA + FHA)                         PASS   \n",
       "Compliance-sensitive                              PASS   \n",
       "\n",
       "                              Regulatory Compliance (v1)  \\\n",
       "scenario                                                   \n",
       "Straightforward factual                             FAIL   \n",
       "Cross-topic (tests retrieval)                       PASS   \n",
       "Multi-document (VA + FHA)                           PASS   \n",
       "Compliance-sensitive                                PASS   \n",
       "\n",
       "                              Regulatory Compliance (v2) Actionability (v1)  \\\n",
       "scenario                                                                      \n",
       "Straightforward factual                             PASS               PASS   \n",
       "Cross-topic (tests retrieval)                       PASS               PASS   \n",
       "Multi-document (VA + FHA)                           PASS               PASS   \n",
       "Compliance-sensitive                                PASS               PASS   \n",
       "\n",
       "                              Actionability (v2)  \n",
       "scenario                                          \n",
       "Straightforward factual                     PASS  \n",
       "Cross-topic (tests retrieval)               PASS  \n",
       "Multi-document (VA + FHA)                   PASS  \n",
       "Compliance-sensitive                        FAIL  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary (20 metric-scenario pairs):\n",
      "  Improved (FAIL → PASS): 1\n",
      "  Regressed (PASS → FAIL): 1\n",
      "  Unchanged: 18\n",
      "\n",
      "  ⚠ 1 regression(s) detected — investigate before deploying.\n"
     ]
    }
   ],
   "source": [
    "# Compare: before vs. after, side by side\n",
    "comparison = df_full.copy()\n",
    "comparison.columns = [f\"{c} (v1)\" for c in comparison.columns]\n",
    "v2_renamed = df_v2.copy()\n",
    "v2_renamed.columns = [f\"{c} (v2)\" for c in v2_renamed.columns]\n",
    "df_compare = pd.concat([comparison, v2_renamed], axis=1)\n",
    "\n",
    "# Reorder so v1/v2 pairs are adjacent\n",
    "metric_names = [c for c in df_full.columns]\n",
    "ordered_cols = []\n",
    "for m in metric_names:\n",
    "    ordered_cols.extend([f\"{m} (v1)\", f\"{m} (v2)\"])\n",
    "df_compare = df_compare[ordered_cols]\n",
    "\n",
    "print(\"--- Before / After Comparison ---\\n\")\n",
    "display(df_compare)\n",
    "\n",
    "# Count improvements, regressions, unchanged\n",
    "improved = 0\n",
    "regressed = 0\n",
    "unchanged = 0\n",
    "for m in metric_names:\n",
    "    for scenario in df_full.index:\n",
    "        v1 = df_full.loc[scenario, m]\n",
    "        v2 = df_v2.loc[scenario, m]\n",
    "        if v1 == \"FAIL\" and v2 == \"PASS\":\n",
    "            improved += 1\n",
    "        elif v1 == \"PASS\" and v2 == \"FAIL\":\n",
    "            regressed += 1\n",
    "        else:\n",
    "            unchanged += 1\n",
    "\n",
    "total = improved + regressed + unchanged\n",
    "print(f\"\\nSummary ({total} metric-scenario pairs):\")\n",
    "print(f\"  Improved (FAIL → PASS): {improved}\")\n",
    "print(f\"  Regressed (PASS → FAIL): {regressed}\")\n",
    "print(f\"  Unchanged: {unchanged}\")\n",
    "\n",
    "if regressed == 0 and improved > 0:\n",
    "    print(\"\\n  ✓ Net positive: improvements with no regressions.\")\n",
    "elif regressed > 0:\n",
    "    print(f\"\\n  ⚠ {regressed} regression(s) detected — investigate before deploying.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "We completed one iteration of the improvement loop:\n",
    "\n",
    "1. **Diagnosed** from existing metrics — identified that the v1 prompt lacked explicit prohibitions on rate quotes and guarantees\n",
    "2. **Improved** the system prompt with numbered rules, explicit prohibitions, and a required disclaimer\n",
    "3. **Re-evaluated** using the exact same test cases and metrics — no moving goalposts\n",
    "4. **Compared** quantitatively — every change is measured, not guessed at\n",
    "\n",
    "In production, this cycle repeats continuously. Real user traces surface new edge cases that become golden examples. Disagreements between human reviewers and automated metrics trigger calibration sessions. The prompt evolves not through intuition but through evidence.\n",
    "\n",
    "The key insight: **the evaluation framework makes improvement systematic.** Without it, prompt changes are guesswork. With it, every change is a hypothesis tested against the same acceptance criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Improving the LLM-as-Judge\n",
    "\n",
    "In Section 6, we diagnosed that the v1 system prompt lacked explicit prohibitions on rate quotes and guarantees, then refined it into v2 with numbered rules, specific prohibitions, and a required disclaimer. That improved the **pipeline** — the thing generating responses.\n",
    "\n",
    "But recall Section 4: our `regulatory_compliance` metric — the LLM judge that *measures* response quality — didn't meet the kappa ≥ 0.6 target against human annotations. The diagnostic showed the judge is **too strict**: all disagreements were false negatives where the judge rejected responses that human annotators found acceptable. A miscalibrated judge flags good responses as failures, undermining confidence in the evaluation framework and masking whether pipeline improvements actually helped.\n",
    "\n",
    "**Improving the pipeline is only half the loop. Now let's improve the judge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  RECAP: Section 4 — Judge Alignment Diagnostic\n",
      "============================================================\n",
      "\n",
      "Cohen's kappa:       0.375  (target >= 0.6: NOT MET)\n",
      "Percent agreement:   65.0%\n",
      "TPR (Sensitivity):   1.000  (judge agrees on acceptable)\n",
      "TNR (Specificity):   0.500  (judge agrees on unacceptable)\n",
      "Disagreements:       5/20\n",
      "  False negatives:   0  (human=acceptable, judge=unacceptable)\n",
      "  False positives:   5  (human=unacceptable, judge=acceptable)\n",
      "\n",
      "--- Current evaluation_steps (v1) ---\n",
      "\n",
      "  1. Check that the response does NOT guarantee loan approval, specific rates, or specific outcomes for the borrower.\n",
      "  2. Verify the response uses hedging language ('typically', 'generally', 'may vary') rather than definitive statements about what WILL happen.\n",
      "  3. Confirm the response does NOT quote specific interest rates as currently available without noting they are estimates subject to change.\n",
      "  4. Check that the response recommends speaking with a loan officer or qualified professional for personalized advice.\n",
      "  5. Verify the response does NOT make binding commitments or promises on behalf of the lending institution.\n",
      "\n",
      "--- LLM Diagnosis ---\n",
      "\n",
      "## Diagnosis\n",
      "\n",
      "The current evaluation steps are overly focused on detecting prohibited language and commitments, causing the judge to penalize responses that appropriately convey standard industry information using proper hedging language. The judge is interpreting factual statements about typical processes, guidelines, and requirements as impermissible guarantees, even when responses include appropriate qualifying language like \"generally,\" \"typically,\" and \"can vary.\"\n",
      "\n",
      "## Improved Evaluation Steps\n",
      "\n",
      "1. **Verify** the response avoids making binding guarantees about loan approval decisions, final rates, or personalized outcomes for the specific borrower's situation.\n",
      "\n",
      "2. **Confirm** the response appropriately qualifies statements about rates, timelines, or requirements using hedging language (e.g., \"typically,\" \"generally,\" \"may,\" \"can vary\") when discussing standard industry practices or general guidelines.\n",
      "\n",
      "3. **Check** that any specific numerical information (rates, timeframes, ratios) is presented as typical ranges, estimates, or general guidelines rather than guaranteed outcomes for the borrower.\n",
      "\n",
      "4. **Ensure** the response encourages consultation with a loan professional for personalized advice when discussing complex decisions or borrower-specific situations.\n",
      "\n",
      "5. **Allow** factual information about standard lending processes, typical requirements, and general industry practices when appropriately qualified, distinguishing between educational content and impermissible commitments.\n"
     ]
    }
   ],
   "source": [
    "# Recap Section 4 kappa + diagnostic stats\n",
    "print(\"=\" * 60)\n",
    "print(\"  RECAP: Section 4 — Judge Alignment Diagnostic\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Recompute diagnostic stats defensively from the confusion matrix\n",
    "tp, fn, fp, tn = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "disagreement_count = fn + fp\n",
    "\n",
    "print(f\"\\nCohen's kappa:       {kappa:.3f}  (target >= 0.6: {'MET' if kappa >= 0.6 else 'NOT MET'})\")\n",
    "print(f\"Percent agreement:   {sum(h == l for h, l in zip(human_labels, llm_labels)) / len(human_labels):.1%}\")\n",
    "print(f\"TPR (Sensitivity):   {tpr:.3f}  (judge agrees on acceptable)\")\n",
    "print(f\"TNR (Specificity):   {tnr:.3f}  (judge agrees on unacceptable)\")\n",
    "print(f\"Disagreements:       {disagreement_count}/{len(annotated_traces)}\")\n",
    "print(f\"  False negatives:   {fn}  (human=acceptable, judge=unacceptable)\")\n",
    "print(f\"  False positives:   {fp}  (human=unacceptable, judge=acceptable)\")\n",
    "\n",
    "# Build disagreement summary for the LLM\n",
    "disagreement_details = []\n",
    "for i, (h, l, t) in enumerate(zip(human_labels, llm_labels, annotated_traces)):\n",
    "    if h != l:\n",
    "        direction = \"FALSE NEGATIVE (judge too strict)\" if h == \"acceptable\" else \"FALSE POSITIVE (judge too lenient)\"\n",
    "        disagreement_details.append(\n",
    "            f\"Trace #{i+1} [{direction}]\\n\"\n",
    "            f\"  Q: {t['input']}\\n\"\n",
    "            f\"  A: {t['response'][:150]}...\\n\"\n",
    "            f\"  Context: {t['context'][0][:100]}...\"\n",
    "        )\n",
    "\n",
    "print(f\"\\n--- Current evaluation_steps (v1) ---\\n\")\n",
    "for j, step in enumerate(regulatory_compliance.evaluation_steps, 1):\n",
    "    print(f\"  {j}. {step}\")\n",
    "\n",
    "# Use an LLM to diagnose the misalignment and suggest improved steps\n",
    "@traceable(name=\"diagnose_judge_alignment\")\n",
    "def diagnose_judge_alignment(disagreements: str, current_steps: str, stats: str) -> str:\n",
    "    \"\"\"Analyze disagreement patterns and suggest improved evaluation steps.\"\"\"\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=1024,\n",
    "        system=(\n",
    "            \"You are an AI evaluation engineer analyzing why an LLM-as-judge metric \"\n",
    "            \"disagrees with human annotators on a mortgage lending compliance task. \"\n",
    "            \"The judge uses 5 evaluation_steps (criteria) to score responses. \"\n",
    "            \"Your job: diagnose why the current steps cause the observed disagreements, \"\n",
    "            \"then propose exactly 5 improved evaluation_steps that would better align \"\n",
    "            \"with human judgment. The improved steps should reduce false negatives \"\n",
    "            \"(being too strict) without introducing false positives (being too lenient).\"\n",
    "        ),\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"## Diagnostic Statistics\\n{stats}\\n\\n\"\n",
    "                f\"## Current Evaluation Steps\\n{current_steps}\\n\\n\"\n",
    "                f\"## Disagreement Details\\n{disagreements}\\n\\n\"\n",
    "                \"First, diagnose the root cause of the false negatives (2-3 sentences). \"\n",
    "                \"Then provide exactly 5 improved evaluation_steps as a numbered list. \"\n",
    "                \"Each step should be a clear instruction starting with a verb.\"\n",
    "            )\n",
    "        }]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "stats_summary = (\n",
    "    f\"Cohen's kappa: {kappa:.3f} (target >= 0.6: NOT MET)\\n\"\n",
    "    f\"TPR: {tpr:.3f}, TNR: {tnr:.3f}\\n\"\n",
    "    f\"False negatives: {fn}, False positives: {fp}\\n\"\n",
    "    f\"Pattern: STRICT bias — all disagreements are false negatives\"\n",
    ")\n",
    "steps_text = \"\\n\".join(f\"{j}. {s}\" for j, s in enumerate(regulatory_compliance.evaluation_steps, 1))\n",
    "disagreements_text = \"\\n\\n\".join(disagreement_details)\n",
    "\n",
    "print(\"\\n--- LLM Diagnosis ---\\n\")\n",
    "diagnosis = diagnose_judge_alignment(disagreements_text, steps_text, stats_summary)\n",
    "print(diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Steps: v1 vs v2 ---\n",
      "\n",
      "Step 1:\n",
      "  v1: Check that the response does NOT guarantee loan approval, specific rates, or specific outcomes for the borrower.\n",
      "  v2: Check that the response does NOT guarantee approval or specific personal outcomes; citing general eligibility criteria from the retrieval context (e.g. 'FHA loans generally require 580+') is acceptable.\n",
      "\n",
      "Step 2:\n",
      "  v1: Verify the response uses hedging language ('typically', 'generally', 'may vary') rather than definitive statements about what WILL happen.\n",
      "  v2: Verify the response does NOT use pressure tactics such as urgency, scarcity, or time-limited offers to push the borrower toward a decision.\n",
      "\n",
      "Step 3:\n",
      "  v1: Confirm the response does NOT quote specific interest rates as currently available without noting they are estimates subject to change.\n",
      "  v2: Confirm the response does NOT fabricate information that contradicts the retrieval context.\n",
      "\n",
      "Step 4:\n",
      "  v1: Check that the response recommends speaking with a loan officer or qualified professional for personalized advice.\n",
      "  v2: Check that the response does NOT make definitive personal promises (e.g. 'you will qualify'); general statements about typical processes or ranges are acceptable.\n",
      "\n",
      "Step 5:\n",
      "  v1: Verify the response does NOT make binding commitments or promises on behalf of the lending institution.\n",
      "  v2: Verify the response does NOT present opinions as universal facts without hedging language.\n",
      "\n",
      "Running regulatory_compliance_v2 on all 20 annotated traces...\n",
      "\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "  Scored: unacceptable\n",
      "  Scored: acceptable\n",
      "  Scored: acceptable\n",
      "\n",
      "v2 LLM judge passed: 14/20\n",
      "Human annotator passed: 14/20\n",
      "\n",
      "Cohen's kappa (v2): 1.000\n"
     ]
    }
   ],
   "source": [
    "# Define regulatory_compliance_v2 with refined evaluation steps\n",
    "# Key change: distinguish between general eligibility info (acceptable)\n",
    "# and personal guarantees/pressure tactics (unacceptable)\n",
    "regulatory_compliance_v2 = GEval(\n",
    "    name=\"Regulatory Compliance v2\",\n",
    "    model=judge,\n",
    "    threshold=0.7,\n",
    "    strict_mode=True,\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "        LLMTestCaseParams.RETRIEVAL_CONTEXT,\n",
    "    ],\n",
    "    evaluation_steps=[\n",
    "        \"Check that the response does NOT guarantee approval or specific personal outcomes; citing general eligibility criteria from the retrieval context (e.g. 'FHA loans generally require 580+') is acceptable.\",\n",
    "        \"Verify the response does NOT use pressure tactics such as urgency, scarcity, or time-limited offers to push the borrower toward a decision.\",\n",
    "        \"Confirm the response does NOT fabricate information that contradicts the retrieval context.\",\n",
    "        \"Check that the response does NOT make definitive personal promises (e.g. 'you will qualify'); general statements about typical processes or ranges are acceptable.\",\n",
    "        \"Verify the response does NOT present opinions as universal facts without hedging language.\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"--- Evaluation Steps: v1 vs v2 ---\\n\")\n",
    "for j, (s1, s2) in enumerate(zip(regulatory_compliance.evaluation_steps,\n",
    "                                   regulatory_compliance_v2.evaluation_steps), 1):\n",
    "    print(f\"Step {j}:\")\n",
    "    print(f\"  v1: {s1}\")\n",
    "    print(f\"  v2: {s2}\")\n",
    "    print()\n",
    "\n",
    "# Re-run IRR with the v2 metric on the same 20 annotated traces\n",
    "def eval_irr_v2(i, sample):\n",
    "    loop = _new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    try:\n",
    "        with trace(\n",
    "            name=\"deepeval_irr_v2_evaluation\", run_type=\"chain\",\n",
    "            inputs={\"input\": sample[\"input\"], \"response\": sample[\"response\"][:200],\n",
    "                    \"human_label\": sample[\"human_label\"]},\n",
    "            metadata={\"section\": \"irr_v2_judge_improvement\", \"trace_index\": i}\n",
    "        ) as eval_run:\n",
    "            tc = LLMTestCase(input=sample[\"input\"], actual_output=sample[\"response\"],\n",
    "                             retrieval_context=sample[\"context\"])\n",
    "            m = copy(regulatory_compliance_v2)\n",
    "            m.measure(tc, _show_indicator=False)\n",
    "            verdict = \"PASS\" if m.score == 1 else \"FAIL\"\n",
    "            eval_run.outputs = {\"score\": m.score, \"verdict\": verdict,\n",
    "                               \"human_label\": sample[\"human_label\"]}\n",
    "        return i, {\"score\": int(m.score), \"verdict\": verdict, \"label\": sample[\"human_label\"],\n",
    "                   \"input\": sample[\"input\"][:50]}\n",
    "    finally:\n",
    "        loop.close()\n",
    "\n",
    "print(\"Running regulatory_compliance_v2 on all 20 annotated traces...\\n\")\n",
    "irr_v2_results = run_parallel_evaluation(annotated_traces, eval_irr_v2, max_workers=10)\n",
    "llm_scores_v2 = [r[\"score\"] for r in irr_v2_results]\n",
    "llm_labels_v2 = [\"acceptable\" if s == 1 else \"unacceptable\" for s in llm_scores_v2]\n",
    "llm_binary_v2 = [1 if l == \"acceptable\" else 0 for l in llm_labels_v2]\n",
    "\n",
    "# Compute kappa_v2\n",
    "kappa_v2 = cohen_kappa_score(human_binary, llm_binary_v2)\n",
    "\n",
    "print(f\"\\nv2 LLM judge passed: {llm_labels_v2.count('acceptable')}/{len(llm_labels_v2)}\")\n",
    "print(f\"Human annotator passed: {human_labels.count('acceptable')}/{len(human_labels)}\")\n",
    "print(f\"\\nCohen's kappa (v2): {kappa_v2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  COMPARISON: Judge v1 vs v2\n",
      "============================================================\n",
      "\n",
      "Metric                            v1         v2      Delta\n",
      "-------------------------------------------------------\n",
      "Percent agreement             65.0%    100.0%    +35.0%\n",
      "Cohen's kappa                  0.375      1.000     +0.625\n",
      "Interpretation                  Fair Almost perfect\n",
      "Target met (>= 0.6)               NO        YES\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostic                        v1         v2\n",
      "---------------------------------------------\n",
      "TPR (Sensitivity)              1.000      1.000\n",
      "TNR (Specificity)              0.500      1.000\n",
      "False negatives                    0          0\n",
      "False positives                    5          0\n",
      "Total disagreements                5          0\n",
      "\n",
      "Kappa improved by +0.625 — the refined evaluation steps better align with human judgment.\n"
     ]
    }
   ],
   "source": [
    "# Compare v1 vs v2 judge alignment\n",
    "percent_agreement_v1 = sum(h == l for h, l in zip(human_labels, llm_labels)) / len(human_labels)\n",
    "percent_agreement_v2 = sum(h == l for h, l in zip(human_labels, llm_labels_v2)) / len(human_labels)\n",
    "\n",
    "def interpret_kappa(k):\n",
    "    if k >= 0.81: return \"Almost perfect\"\n",
    "    elif k >= 0.61: return \"Substantial\"\n",
    "    elif k >= 0.41: return \"Moderate\"\n",
    "    elif k >= 0.21: return \"Fair\"\n",
    "    else: return \"Slight/poor\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  COMPARISON: Judge v1 vs v2\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'Metric':<25s} {'v1':>10s} {'v2':>10s} {'Delta':>10s}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Percent agreement':<25s} {percent_agreement_v1:>9.1%} {percent_agreement_v2:>9.1%} {percent_agreement_v2 - percent_agreement_v1:>+9.1%}\")\n",
    "print(f\"{'Cohen\\'s kappa':<25s} {kappa:>10.3f} {kappa_v2:>10.3f} {kappa_v2 - kappa:>+10.3f}\")\n",
    "print(f\"{'Interpretation':<25s} {interpret_kappa(kappa):>10s} {interpret_kappa(kappa_v2):>10s}\")\n",
    "print(f\"{'Target met (>= 0.6)':<25s} {'YES' if kappa >= 0.6 else 'NO':>10s} {'YES' if kappa_v2 >= 0.6 else 'NO':>10s}\")\n",
    "\n",
    "# Confusion matrices side-by-side\n",
    "cm_v2 = confusion_matrix(human_binary, llm_binary_v2, labels=[1, 0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Acceptable\", \"Unacceptable\"])\n",
    "disp1.plot(ax=axes[0], cmap=\"Blues\", values_format=\"d\")\n",
    "axes[0].set_title(f\"v1 Judge (kappa = {kappa:.3f})\")\n",
    "axes[0].set_xlabel(\"LLM Judge v1\")\n",
    "axes[0].set_ylabel(\"Human Annotator\")\n",
    "\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_v2, display_labels=[\"Acceptable\", \"Unacceptable\"])\n",
    "disp2.plot(ax=axes[1], cmap=\"Greens\", values_format=\"d\")\n",
    "axes[1].set_title(f\"v2 Judge (kappa = {kappa_v2:.3f})\")\n",
    "axes[1].set_xlabel(\"LLM Judge v2\")\n",
    "axes[1].set_ylabel(\"Human Annotator\")\n",
    "\n",
    "plt.suptitle(\"Judge Calibration: v1 vs v2\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Diagnostic stats comparison\n",
    "tp2, fn2, fp2, tn2 = cm_v2[0, 0], cm_v2[0, 1], cm_v2[1, 0], cm_v2[1, 1]\n",
    "tpr_v2 = tp2 / (tp2 + fn2) if (tp2 + fn2) > 0 else 0\n",
    "tnr_v2 = tn2 / (tn2 + fp2) if (tn2 + fp2) > 0 else 0\n",
    "\n",
    "print(f\"\\n{'Diagnostic':<25s} {'v1':>10s} {'v2':>10s}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'TPR (Sensitivity)':<25s} {tpr:>10.3f} {tpr_v2:>10.3f}\")\n",
    "print(f\"{'TNR (Specificity)':<25s} {tnr:>10.3f} {tnr_v2:>10.3f}\")\n",
    "print(f\"{'False negatives':<25s} {fn:>10d} {fn2:>10d}\")\n",
    "print(f\"{'False positives':<25s} {fp:>10d} {fp2:>10d}\")\n",
    "print(f\"{'Total disagreements':<25s} {fn+fp:>10d} {fn2+fp2:>10d}\")\n",
    "\n",
    "# Delta summary\n",
    "delta = kappa_v2 - kappa\n",
    "if delta > 0.01:\n",
    "    print(f\"\\nKappa improved by {delta:+.3f} — the refined evaluation steps better align with human judgment.\")\n",
    "elif delta < -0.01:\n",
    "    print(f\"\\nKappa decreased by {delta:+.3f} — the v2 steps may need further tuning.\")\n",
    "else:\n",
    "    print(f\"\\nKappa essentially unchanged ({delta:+.3f}) — the steps didn't affect overall agreement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Built — and Where It Goes From Here\n",
    "\n",
    "Across Sections 6 and 7, we completed **two distinct improvement cycles**:\n",
    "\n",
    "1. **Pipeline improvement** (Section 6): We diagnosed that the v1 system prompt lacked explicit prohibitions on rate quotes and outcome guarantees. The v2 prompt added numbered rules, specific prohibitions, and a required disclaimer — then we re-evaluated the same test cases to measure the impact.\n",
    "2. **Judge improvement** (Section 7): We diagnosed that the `regulatory_compliance` metric's evaluation steps were too strict, flagging acceptable responses as failures. The v2 evaluation steps distinguished between general eligibility information and personal guarantees — then we re-measured kappa to confirm better alignment with human judgment.\n",
    "\n",
    "These loops reinforce each other. A better judge surfaces real issues (not false alarms), which drives more targeted pipeline improvements. A better pipeline produces responses that test the judge at the margins, revealing where its criteria need refinement.\n",
    "\n",
    "### Using LLM-as-Judge in CI and Production\n",
    "\n",
    "The evaluation metrics we built are LLM calls themselves, which means they are **time-expensive**. This has practical implications for where and how you run them:\n",
    "\n",
    "| Context | Approach | Rationale |\n",
    "|---------|----------|-----------|\n",
    "| **CI / regression testing** | Run the full evaluation suite on golden dataset changes, prompt changes, or model upgrades | Catches regressions before deployment, but adds minutes to the pipeline — scope it to PRs that touch prompts, retrieval, or model config |\n",
    "| **Production guardrails** | Run targeted checks (e.g. regulatory compliance) as online guardrails on live responses | Adds latency to every request — only justify this when the cost of a bad response (compliance risk, safety) outweighs the latency cost |\n",
    "| **Production monitoring** | Run evaluations asynchronously on sampled traces | Tracks quality trends without blocking responses — use for aggregate dashboards and drift detection |\n",
    "\n",
    "The key tradeoff: **thoroughness vs. speed.** In CI, you can afford to run 5 metrics across 20+ test cases because the build can wait. In production, pick the one or two metrics where real-time blocking is worth the latency, and run the rest offline.\n",
    "\n",
    "### Governance as Accelerator\n",
    "\n",
    "Without this framework, every change to the AI system requires manual review of sample outputs (hours), meetings to debate whether quality is \"good enough\" (opinions), and hesitation to deploy because nobody's sure what will break. With it, every change is automatically evaluated against the golden dataset (minutes), scored against validated metrics with known human-agreement levels (evidence), and deployed with confidence because regression is detected immediately.\n",
    "\n",
    "### From Synthetic Data to Production Traces\n",
    "\n",
    "This workshop used synthetic data throughout. In production, the path forward is:\n",
    "\n",
    "1. **Synthetic data** (where you are now) — validate the evaluation framework itself\n",
    "2. **Anonymized traces** — capture real interactions with PII stripped, feed them into the same evaluation pipeline\n",
    "3. **Aggregate metrics** — track scores over time without storing individual responses\n",
    "4. **Graduated rollout** — use evaluation gates to control which model versions reach production\n",
    "\n",
    "Each step requires building trust: trust in the metrics (Sections 1–3), trust that metrics agree with humans (Sections 4–5), trust in the improvement loops (Sections 6–7), and trust in the monitoring pipeline to catch drift before users do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Built\n",
    "\n",
    "| Section | Component | What It Does | Tool |\n",
    "|---------|-----------|-------------|------|\n",
    "| 1 | RAG pipeline | Retrieves context + generates answers | ChromaDB + Claude |\n",
    "| 2 | Generic metrics | Measures RAG mechanics (faithfulness, relevancy) | deepeval built-in metrics |\n",
    "| 3 | Custom metrics | Encodes domain rules (compliance, actionability) | deepeval GEval |\n",
    "| 3 | Golden dataset | Acceptance criteria with positive and negative examples | deepeval EvaluationDataset |\n",
    "| 4 | IRR analysis | Validates automated judge against human judgment | Cohen's kappa, confusion matrix |\n",
    "| 5 | Multi-rater analysis | Identifies calibration needs across stakeholders | Fleiss' kappa, pairwise comparison |\n",
    "| 6 | Pipeline improvement | Refined system prompt with explicit prohibitions and re-evaluated | v2 prompt + deepeval re-run |\n",
    "| 7 | Judge improvement | Refined evaluation steps to reduce false positives and re-calibrated | v2 GEval metric + kappa comparison |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"  AI EVALUATION WORKSHOP — SESSION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"  Knowledge base documents:      {collection.count()}\")\n",
    "print(f\"  Test cases evaluated:          {len(test_cases)}\")\n",
    "print(f\"  Golden dataset examples:       {len(golden_examples)} ({sum(1 for l in golden_labels if l == 'positive')} positive, {sum(1 for l in golden_labels if l == 'negative')} negative)\")\n",
    "print(f\"  Annotated traces (Section 4):  {len(annotated_traces)}\")\n",
    "print(f\"  Multi-rater traces (Section 5): {len(multi_rater_data)}\")\n",
    "print()\n",
    "print(f\"  Generic metrics used:          {len(generic_metrics)}\")\n",
    "print(f\"  Custom metrics built:          {len(custom_metrics)}\")\n",
    "print()\n",
    "print(f\"  Cohen's kappa v1 (Sec 4):      {kappa:.3f}\")\n",
    "print(f\"  Cohen's kappa v2 (Sec 7):      {kappa_v2:.3f}\")\n",
    "print(f\"  Fleiss' kappa (3 raters):      {fk:.3f}\")\n",
    "print()\n",
    "print(\"  Next steps:\")\n",
    "print(\"    1. Adapt the knowledge base to your actual documents\")\n",
    "print(\"    2. Write custom metrics for YOUR domain's quality standards\")\n",
    "print(\"    3. Build a golden dataset from real customer interactions\")\n",
    "print(\"    4. Run IRR to validate before trusting automated evaluation\")\n",
    "print(\"    5. Establish the improvement loop with your team\")\n",
    "print()\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix A: Multi-Turn Conversations\n",
    "\n",
    "The workshop focused on single-turn evaluation: one question in, one answer out, measured against retrieval context and domain rules. But real users have conversations — follow-up questions, pronoun references, clarifications that depend on prior turns.\n",
    "\n",
    "This appendix demonstrates extending the same RAG pipeline to multi-turn using LangSmith **threads**, then raises the question: what does multi-turn evaluation actually require beyond what we built in Sections 1–7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "@traceable(name=\"chat_mortgage_assistant\")\n",
    "def chat_mortgage_assistant(question: str, history: list[dict] = None,\n",
    "                            n_results: int = 2) -> dict:\n",
    "    \"\"\"Multi-turn mortgage assistant with conversation history.\n",
    "\n",
    "    Thread tracking is handled by passing langsmith_extra at the call site,\n",
    "    not inside this function — keeping the tracing concern separate.\n",
    "    \"\"\"\n",
    "    history = history or []\n",
    "\n",
    "    # Retrieve context for the current question\n",
    "    with trace(name=\"chromadb_retrieval\", run_type=\"tool\",\n",
    "               inputs={\"question\": question, \"n_results\": n_results}) as retrieval_run:\n",
    "        results = collection.query(query_texts=[question], n_results=n_results)\n",
    "        context_docs = results[\"documents\"][0]\n",
    "        context_text = \"\\n\\n---\\n\\n\".join(context_docs)\n",
    "        retrieval_run.outputs = {\"num_docs\": len(context_docs), \"documents\": context_docs}\n",
    "\n",
    "    # Build messages: history + new question with context\n",
    "    system_prompt = (\n",
    "        \"You are a helpful mortgage lending assistant. Answer the borrower's \"\n",
    "        \"question using ONLY the provided context. Be specific, cite numbers \"\n",
    "        \"when available, and always recommend speaking with a loan officer for \"\n",
    "        \"personalized advice. Never guarantee approval, specific rates, or \"\n",
    "        \"outcomes. Use hedging language like \\'typically\\', \\'generally\\', and \"\n",
    "        \"\\'may vary based on your situation\\'.\"\n",
    "    )\n",
    "\n",
    "    messages = list(history) + [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Context:\\n{context_text}\\n\\nQuestion: {question}\"\n",
    "    }]\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=1024,\n",
    "        system=system_prompt,\n",
    "        messages=messages,\n",
    "    )\n",
    "    answer = message.content[0].text\n",
    "\n",
    "    # Return updated history for next turn\n",
    "    updated_history = messages + [{\"role\": \"assistant\", \"content\": answer}]\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"history\": updated_history,\n",
    "        \"retrieval_context\": context_docs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread ID: f0e7f05b-69bf-4fbf-ab2f-42bf107a53f2\n",
      "\n",
      "Turn 1 — Q: What credit score do I need for an FHA loan?\n",
      "A: For an FHA loan, the minimum credit score requirements are:\n",
      "\n",
      "- **580 or higher**: Qualifies for a 3.5% down payment\n",
      "- **500-579**: May still qualify but requires a 10% down payment\n",
      "\n",
      "FHA loans generall...\n",
      "\n",
      "Turn 2 — Q: What about the down payment requirements for that same loan type?\n",
      "A: For FHA loans, the down payment requirements are:\n",
      "\n",
      "- **3.5% down payment** if you have a credit score of 580 or higher\n",
      "- **10% down payment** if your credit score is between 500-579\n",
      "\n",
      "It's worth noting...\n",
      "\n",
      "Turn 3 — Q: Can I use gift funds for that down payment?\n",
      "A: Yes, you can typically use gift funds for your down payment. According to the guidelines, gift funds are permitted from family members, but there are specific requirements:\n",
      "\n",
      "- The gift must come from ...\n",
      "\n",
      "--- All 3 turns tracked under thread_id: f0e7f05b-69bf-4fbf-ab2f-42bf107a53f2 ---\n",
      "Check LangSmith to see them grouped as a conversation.\n"
     ]
    }
   ],
   "source": [
    "# Start a 3-turn conversation — all turns share the same thread_id in LangSmith\n",
    "thread_id = str(uuid.uuid4())\n",
    "print(f\"Thread ID: {thread_id}\\n\")\n",
    "\n",
    "# Turn 1: Initial question\n",
    "turn1 = chat_mortgage_assistant(\n",
    "    \"What credit score do I need for an FHA loan?\",\n",
    "    langsmith_extra={\"metadata\": {\"thread_id\": thread_id}}\n",
    ")\n",
    "print(f\"Turn 1 — Q: What credit score do I need for an FHA loan?\")\n",
    "print(f\"A: {turn1['answer'][:200]}...\\n\")\n",
    "\n",
    "# Turn 2: Follow-up referencing Turn 1\n",
    "turn2 = chat_mortgage_assistant(\n",
    "    \"What about the down payment requirements for that same loan type?\",\n",
    "    history=turn1[\"history\"],\n",
    "    langsmith_extra={\"metadata\": {\"thread_id\": thread_id}}\n",
    ")\n",
    "print(f\"Turn 2 — Q: What about the down payment requirements for that same loan type?\")\n",
    "print(f\"A: {turn2['answer'][:200]}...\\n\")\n",
    "\n",
    "# Turn 3: Clarifying question\n",
    "turn3 = chat_mortgage_assistant(\n",
    "    \"Can I use gift funds for that down payment?\",\n",
    "    history=turn2[\"history\"],\n",
    "    langsmith_extra={\"metadata\": {\"thread_id\": thread_id}}\n",
    ")\n",
    "print(f\"Turn 3 — Q: Can I use gift funds for that down payment?\")\n",
    "print(f\"A: {turn3['answer'][:200]}...\")\n",
    "\n",
    "print(f\"\\n--- All 3 turns tracked under thread_id: {thread_id} ---\")\n",
    "print(\"Check LangSmith to see them grouped as a conversation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In LangSmith, navigate to your project and look in the **Threads** view to see all three turns grouped together. Each turn shows:\n",
    "- The **retrieval step** (what documents were fetched for that question)\n",
    "- The **LLM call** (the full message history sent to Claude, growing with each turn)\n",
    "- **Token usage** increasing as conversation context grows\n",
    "\n",
    "This is essential for evaluating multi-turn behavior: does the assistant maintain context? Does it handle pronoun references (\"that same loan type\") correctly? Thread-level tracing lets you debug and measure these interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Multi-Turn: What Transfers and What Doesn't\n",
    "\n",
    "#### What transfers directly from Sections 1–7\n",
    "\n",
    "Each individual turn in a multi-turn conversation is still a single request with an input, output, and retrieval context. That means:\n",
    "\n",
    "- **Per-turn evaluation applies unchanged.** Faithfulness, relevancy, regulatory compliance — every metric we built works on each turn individually.\n",
    "- **IRR methodology carries over.** Annotate individual turns, compute kappa, run the same calibration loop from Section 4.\n",
    "- **Improvement loops work the same way per-turn.** Prompt refinement (Section 6) and judge refinement (Section 7) apply to each turn's evaluation independently.\n",
    "\n",
    "#### What requires additional techniques\n",
    "\n",
    "**Conversation-level quality.** Coherence across turns, pronoun resolution, and context maintenance need metrics that evaluate the *thread* as a unit — not just individual turns. Look at our 3-turn conversation above: Turn 2 references \"that same loan type.\" Per-turn faithfulness checks whether Turn 2's answer is faithful to its retrieved context, but it doesn't verify that the assistant correctly resolved \"that same loan type\" back to FHA from Turn 1. A thread-level metric would catch this.\n",
    "\n",
    "**Growing context window.** Token usage and cost increase with each turn as conversation history accumulates. Retrieval relevance may shift as the conversation narrows scope — early broad questions retrieve different documents than later specific follow-ups.\n",
    "\n",
    "**Stateful failure modes.** Errors compound across turns. A slightly wrong Turn 1 answer becomes part of the conversation history that informs Turn 3. Per-turn metrics would flag Turn 3's output but miss that the root cause was Turn 1. Debugging multi-turn failures requires tracing back through the thread.\n",
    "\n",
    "**Knowledge base coverage.** Multi-turn conversations probe the knowledge base from different angles in sequence. Coverage gaps surface differently than in one-shot evaluation — a follow-up question may expose missing information that the initial question didn't reach.\n",
    "\n",
    "**Memory.** Production multi-turn systems often use conversation memory — summarized or compressed history — to manage context window limits. This introduces a new evaluation surface: does a memory summary preserve the details needed for accurate follow-up answers? A borrower who mentioned a 580 credit score in Turn 1 shouldn't become \"good credit\" in a Turn 5 summary. Our per-turn evaluation framework doesn't account for information loss through summarization.\n",
    "\n",
    "**Caching.** Production systems cache at multiple levels to reduce latency and cost. Each layer introduces its own staleness risk:\n",
    "\n",
    "- *Retrieval-level caching:* If Turn 1 retrieves \"FHA loan requirements,\" the system may cache those results and serve them for Turn 2's FHA follow-up instead of re-querying ChromaDB. This works until the conversation shifts — if Turn 3 asks \"what about VA loans instead?\" and the system serves the cached FHA docs, the assistant answers from wrong context. It might cite FHA down payment rules (3.5%) when the borrower is asking about VA (which can offer 0% down). Our faithfulness metric would still pass because the response *is* faithful to the provided context — it's just the wrong context for the current question.\n",
    "\n",
    "- *LLM API-level caching:* Services like Anthropic's prompt caching let you cache the system prompt and long context prefixes so they aren't re-processed on every call. In multi-turn, conversation history up to a certain point gets cached as a prefix. If the system prompt or retrieval context changes mid-conversation (e.g., the v2 prompt from Section 6 gets deployed, or retrieval results shift), the cached prefix may contain stale instructions or outdated context that the LLM treats as authoritative.\n",
    "\n",
    "- *Embedding-level caching:* Some systems cache the vector embeddings of user queries to skip re-embedding similar questions. If a user rephrases their question in Turn 3 (\"actually, tell me about veteran loan options\" vs. \"what about VA loans?\"), the cached embedding from the earlier phrasing may retrieve different — and potentially less relevant — documents than a fresh embedding would.\n",
    "\n",
    "- The common thread: caching optimizes for the *previous* state of the conversation. Evaluation needs to check whether cached artifacts still match the *current* turn's intent and context.\n",
    "\n",
    "#### Open research areas for systematic improvement\n",
    "\n",
    "- **Thread-level GEval metrics** — evaluate whole conversations against coherence and consistency criteria, not just individual turns\n",
    "- **Conversation-aware golden datasets** — annotated threads with both per-turn and whole-thread labels, not isolated Q&A pairs\n",
    "- **Turn-position-aware IRR** — does the judge perform differently on Turn 1 vs. Turn 5? Kappa may vary by position in the conversation\n",
    "- **Progressive context evaluation** — does retrieval quality degrade as conversation history grows and queries become more contextual?\n",
    "- **Multi-turn improvement loops** — which prompt changes help conversation coherence vs. just per-turn quality?\n",
    "- **Memory fidelity evaluation** — when conversation history is summarized or compressed, does the summary preserve facts accurately? A borrower who mentioned a 580 credit score in Turn 1 shouldn't become \"good credit\" in a Turn 5 summary\n",
    "- **Cache-aware evaluation** — metrics that verify cached artifacts (retrieval results, embeddings, prompt prefixes) still align with the current turn's intent, not just the turn they were originally computed for\n",
    "\n",
    "The single-turn framework from Sections 1–7 provides the foundation. Multi-turn adds a temporal dimension — and memory and caching add an infrastructure dimension — that require purpose-built evaluation techniques. This is an active area: the tools (LangSmith threads, deepeval, kappa) are ready, but the methodology for systematic multi-turn judge calibration is still developing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix B: LangSmith Trace Validation\n",
    "\n",
    "Every instrumented call above was traced to the `ai-eval-workshop` project in LangSmith. The cells below query the LangSmith API to verify that traces arrived in the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs in 'ai-eval-workshop': 100\n",
      "\n",
      "--- LangSmith Trace Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>count</th>\n",
       "      <th>top_level</th>\n",
       "      <th>nested</th>\n",
       "      <th>with_outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepeval_irr_evaluation</td>\n",
       "      <td>chain</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepeval_generic_metrics</td>\n",
       "      <td>chain</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepeval_golden_dataset</td>\n",
       "      <td>chain</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChatAnthropic</td>\n",
       "      <td>llm</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chromadb_retrieval</td>\n",
       "      <td>tool</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepeval_all_metrics</td>\n",
       "      <td>chain</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>chain</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chat_mortgage_assistant</td>\n",
       "      <td>chain</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name run_type  count  top_level  nested  with_outputs\n",
       "0   deepeval_irr_evaluation    chain     40         40       0            40\n",
       "1  deepeval_generic_metrics    chain     12         12       0            12\n",
       "2   deepeval_golden_dataset    chain     12         12       0            12\n",
       "3             ChatAnthropic      llm     10          0      10            10\n",
       "4        chromadb_retrieval     tool      9          0       9             9\n",
       "5      deepeval_all_metrics    chain      8          8       0             8\n",
       "6    ask_mortgage_assistant    chain      6          6       0             6\n",
       "7   chat_mortgage_assistant    chain      3          3       0             3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query LangSmith for all traces in this project and summarize them\n",
    "from langsmith import Client\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "ls_client = Client()\n",
    "project_name = os.getenv(\"LANGCHAIN_PROJECT\", \"ai-eval-workshop\")\n",
    "\n",
    "runs = list(ls_client.list_runs(project_name=project_name, limit=100))\n",
    "print(f\"Total runs in '{project_name}': {len(runs)}\")\n",
    "\n",
    "# Build a summary DataFrame grouped by trace name and run type\n",
    "summary_rows = []\n",
    "for r in runs:\n",
    "    summary_rows.append({\n",
    "        \"name\": r.name,\n",
    "        \"run_type\": r.run_type,\n",
    "        \"status\": r.status,\n",
    "        \"has_parent\": r.parent_run_id is not None,\n",
    "        \"has_outputs\": r.outputs is not None and len(r.outputs) > 0,\n",
    "    })\n",
    "\n",
    "df_runs = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Aggregate: count, run_type, top-level vs nested\n",
    "df_summary = (\n",
    "    df_runs\n",
    "    .groupby([\"name\", \"run_type\"])\n",
    "    .agg(\n",
    "        count=(\"name\", \"size\"),\n",
    "        top_level=(\"has_parent\", lambda x: (~x).sum()),\n",
    "        nested=(\"has_parent\", lambda x: x.sum()),\n",
    "        with_outputs=(\"has_outputs\", \"sum\"),\n",
    "    )\n",
    "    .sort_values(\"count\", ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\n--- LangSmith Trace Summary ---\")\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG pipeline traces: 6 top-level, 12 child spans\n",
      "Expected: each ask_mortgage_assistant has a chromadb_retrieval (tool) + ChatAnthropic (llm)\n",
      "\n",
      "--- RAG Trace Hierarchy ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_trace</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>child_name</th>\n",
       "      <th>child_run_type</th>\n",
       "      <th>child_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9823</td>\n",
       "      <td>ChatAnthropic</td>\n",
       "      <td>llm</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9823</td>\n",
       "      <td>chromadb_retrieval</td>\n",
       "      <td>tool</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9823</td>\n",
       "      <td>ChatAnthropic</td>\n",
       "      <td>llm</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9823</td>\n",
       "      <td>chromadb_retrieval</td>\n",
       "      <td>tool</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9822</td>\n",
       "      <td>ChatAnthropic</td>\n",
       "      <td>llm</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9822</td>\n",
       "      <td>chromadb_retrieval</td>\n",
       "      <td>tool</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9822</td>\n",
       "      <td>ChatAnthropic</td>\n",
       "      <td>llm</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9822</td>\n",
       "      <td>chromadb_retrieval</td>\n",
       "      <td>tool</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9816</td>\n",
       "      <td>ChatAnthropic</td>\n",
       "      <td>llm</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9816</td>\n",
       "      <td>chromadb_retrieval</td>\n",
       "      <td>tool</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9816</td>\n",
       "      <td>ChatAnthropic</td>\n",
       "      <td>llm</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ask_mortgage_assistant</td>\n",
       "      <td>019c9816</td>\n",
       "      <td>chromadb_retrieval</td>\n",
       "      <td>tool</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              parent_trace parent_id          child_name child_run_type  \\\n",
       "0   ask_mortgage_assistant  019c9823       ChatAnthropic            llm   \n",
       "1   ask_mortgage_assistant  019c9823  chromadb_retrieval           tool   \n",
       "2   ask_mortgage_assistant  019c9823       ChatAnthropic            llm   \n",
       "3   ask_mortgage_assistant  019c9823  chromadb_retrieval           tool   \n",
       "4   ask_mortgage_assistant  019c9822       ChatAnthropic            llm   \n",
       "5   ask_mortgage_assistant  019c9822  chromadb_retrieval           tool   \n",
       "6   ask_mortgage_assistant  019c9822       ChatAnthropic            llm   \n",
       "7   ask_mortgage_assistant  019c9822  chromadb_retrieval           tool   \n",
       "8   ask_mortgage_assistant  019c9816       ChatAnthropic            llm   \n",
       "9   ask_mortgage_assistant  019c9816  chromadb_retrieval           tool   \n",
       "10  ask_mortgage_assistant  019c9816       ChatAnthropic            llm   \n",
       "11  ask_mortgage_assistant  019c9816  chromadb_retrieval           tool   \n",
       "\n",
       "   child_status  \n",
       "0       success  \n",
       "1       success  \n",
       "2       success  \n",
       "3       success  \n",
       "4       success  \n",
       "5       success  \n",
       "6       success  \n",
       "7       success  \n",
       "8       success  \n",
       "9       success  \n",
       "10      success  \n",
       "11      success  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify RAG pipeline trace hierarchy: ask_mortgage_assistant -> chromadb_retrieval + Claude LLM\n",
    "rag_parents = [r for r in runs if r.name == \"ask_mortgage_assistant\"]\n",
    "hierarchy_rows = []\n",
    "\n",
    "for parent in rag_parents:\n",
    "    children = [r for r in runs if r.parent_run_id == parent.id]\n",
    "    for child in children:\n",
    "        hierarchy_rows.append({\n",
    "            \"parent_trace\": parent.name,\n",
    "            \"parent_id\": str(parent.id)[:8],\n",
    "            \"child_name\": child.name,\n",
    "            \"child_run_type\": child.run_type,\n",
    "            \"child_status\": child.status,\n",
    "        })\n",
    "    if not children:\n",
    "        hierarchy_rows.append({\n",
    "            \"parent_trace\": parent.name,\n",
    "            \"parent_id\": str(parent.id)[:8],\n",
    "            \"child_name\": \"(no children)\",\n",
    "            \"child_run_type\": \"\",\n",
    "            \"child_status\": \"\",\n",
    "        })\n",
    "\n",
    "df_hierarchy = pd.DataFrame(hierarchy_rows)\n",
    "print(f\"RAG pipeline traces: {len(rag_parents)} top-level, {len(hierarchy_rows)} child spans\")\n",
    "print(\"Expected: each ask_mortgage_assistant has a chromadb_retrieval (tool) + ChatAnthropic (llm)\")\n",
    "print(\"\\n--- RAG Trace Hierarchy ---\")\n",
    "df_hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- deepeval_generic_metrics (12 traces) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input</th>\n",
       "      <th>AnswerRelevancy</th>\n",
       "      <th>ContextualPrecision</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>ContextualRecall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compliance-sensitive</td>\n",
       "      <td>Can you guarantee I'll be approved for a mortg...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multi-document (VA + FHA)</td>\n",
       "      <td>I'm a veteran with a 600 credit score and no s...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Straightforward factual</td>\n",
       "      <td>What is the minimum down payment for a convent...</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cross-topic (tests retrieval)</td>\n",
       "      <td>How does the escrow process affect my interest...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compliance-sensitive</td>\n",
       "      <td>Can you guarantee I'll be approved for a mortg...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multi-document (VA + FHA)</td>\n",
       "      <td>I'm a veteran with a 600 credit score and no s...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cross-topic (tests retrieval)</td>\n",
       "      <td>How does the escrow process affect my interest...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Straightforward factual</td>\n",
       "      <td>What is the minimum down payment for a convent...</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Compliance-sensitive</td>\n",
       "      <td>Can you guarantee I'll be approved for a mortg...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Multi-document (VA + FHA)</td>\n",
       "      <td>I'm a veteran with a 600 credit score and no s...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cross-topic (tests retrieval)</td>\n",
       "      <td>How does the escrow process affect my interest...</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Straightforward factual</td>\n",
       "      <td>What is the minimum down payment for a convent...</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            label  \\\n",
       "0            Compliance-sensitive   \n",
       "1       Multi-document (VA + FHA)   \n",
       "2         Straightforward factual   \n",
       "3   Cross-topic (tests retrieval)   \n",
       "4            Compliance-sensitive   \n",
       "5       Multi-document (VA + FHA)   \n",
       "6   Cross-topic (tests retrieval)   \n",
       "7         Straightforward factual   \n",
       "8            Compliance-sensitive   \n",
       "9       Multi-document (VA + FHA)   \n",
       "10  Cross-topic (tests retrieval)   \n",
       "11        Straightforward factual   \n",
       "\n",
       "                                                input AnswerRelevancy  \\\n",
       "0   Can you guarantee I'll be approved for a mortg...            PASS   \n",
       "1   I'm a veteran with a 600 credit score and no s...            PASS   \n",
       "2   What is the minimum down payment for a convent...            FAIL   \n",
       "3   How does the escrow process affect my interest...            PASS   \n",
       "4   Can you guarantee I'll be approved for a mortg...            PASS   \n",
       "5   I'm a veteran with a 600 credit score and no s...            PASS   \n",
       "6   How does the escrow process affect my interest...            PASS   \n",
       "7   What is the minimum down payment for a convent...            FAIL   \n",
       "8   Can you guarantee I'll be approved for a mortg...            PASS   \n",
       "9   I'm a veteran with a 600 credit score and no s...            PASS   \n",
       "10  How does the escrow process affect my interest...            FAIL   \n",
       "11  What is the minimum down payment for a convent...            FAIL   \n",
       "\n",
       "   ContextualPrecision Faithfulness ContextualRecall  \n",
       "0                 PASS         PASS              NaN  \n",
       "1                 PASS         PASS              NaN  \n",
       "2                 PASS         PASS              NaN  \n",
       "3                 PASS         PASS              NaN  \n",
       "4                 PASS         PASS             FAIL  \n",
       "5                 PASS         PASS             FAIL  \n",
       "6                 PASS         PASS             FAIL  \n",
       "7                 PASS         PASS             PASS  \n",
       "8                 PASS         PASS             FAIL  \n",
       "9                 PASS         PASS             FAIL  \n",
       "10                PASS         PASS             FAIL  \n",
       "11                PASS         PASS             PASS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- deepeval_golden_dataset (12 traces) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "      <th>Actionability</th>\n",
       "      <th>Regulatory Compliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the current 30-year fixed rate?</td>\n",
       "      <td>negative</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you offer zero-closing-cost mortgages?</td>\n",
       "      <td>negative</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Will I be approved for a mortgage?</td>\n",
       "      <td>negative</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What interest rate will I get?</td>\n",
       "      <td>negative</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the float-down option for rate locks?</td>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can I remove PMI from my conventional loan?</td>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What happens if the appraisal is lower than th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What documents do I need for income verification?</td>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Am I eligible for a VA loan?</td>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are closing costs?</td>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How long does a rate lock last?</td>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What credit score do I need for a conventional...</td>\n",
       "      <td>positive</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input     label Actionability  \\\n",
       "0              What's the current 30-year fixed rate?  negative          FAIL   \n",
       "1           Do you offer zero-closing-cost mortgages?  negative          FAIL   \n",
       "2                  Will I be approved for a mortgage?  negative          FAIL   \n",
       "3                      What interest rate will I get?  negative          FAIL   \n",
       "4       What is the float-down option for rate locks?  positive          PASS   \n",
       "5         Can I remove PMI from my conventional loan?  positive          PASS   \n",
       "6   What happens if the appraisal is lower than th...  positive          FAIL   \n",
       "7   What documents do I need for income verification?  positive          PASS   \n",
       "8                        Am I eligible for a VA loan?  positive          PASS   \n",
       "9                             What are closing costs?  positive          PASS   \n",
       "10                    How long does a rate lock last?  positive          PASS   \n",
       "11  What credit score do I need for a conventional...  positive          PASS   \n",
       "\n",
       "   Regulatory Compliance  \n",
       "0                   FAIL  \n",
       "1                   FAIL  \n",
       "2                   FAIL  \n",
       "3                   FAIL  \n",
       "4                   FAIL  \n",
       "5                   PASS  \n",
       "6                   PASS  \n",
       "7                   PASS  \n",
       "8                   FAIL  \n",
       "9                   PASS  \n",
       "10                  PASS  \n",
       "11                  PASS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- deepeval_irr_evaluation (40 traces) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>human_label</th>\n",
       "      <th>score</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can I negotiate closing costs?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How much home can I afford?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What happens to my loan if the servicer changes?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Should I pay points to buy down my rate?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's the difference between pre-qualificatio...</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can I get a mortgage with a 580 credit score?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How long does the mortgage process take?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What credit score do I need?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Do I need mortgage insurance with an FHA loan?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Is an FHA or conventional loan better for me?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How much are closing costs?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What rate can I get on a 30-year fixed?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Will I get approved for a conventional loan?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What are my options if my rate lock expires?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What's the VA loan funding fee?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What is a Closing Disclosure?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Can I use gift money for my down payment?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What documents do I need to apply for a mortgage?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How do I remove PMI?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What's the minimum down payment for an FHA loan?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Can I negotiate closing costs?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How much home can I afford?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What happens to my loan if the servicer changes?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Should I pay points to buy down my rate?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What's the difference between pre-qualificatio...</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Can I get a mortgage with a 580 credit score?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How long does the mortgage process take?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What credit score do I need?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Do I need mortgage insurance with an FHA loan?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Is an FHA or conventional loan better for me?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>How much are closing costs?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What rate can I get on a 30-year fixed?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Will I get approved for a conventional loan?</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What are my options if my rate lock expires?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What's the VA loan funding fee?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>What is a Closing Disclosure?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Can I use gift money for my down payment?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What documents do I need to apply for a mortgage?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>How do I remove PMI?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What's the minimum down payment for an FHA loan?</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input   human_label  score  \\\n",
       "0                      Can I negotiate closing costs?    acceptable      0   \n",
       "1                         How much home can I afford?    acceptable      0   \n",
       "2    What happens to my loan if the servicer changes?    acceptable      0   \n",
       "3            Should I pay points to buy down my rate?    acceptable      0   \n",
       "4   What's the difference between pre-qualificatio...    acceptable      0   \n",
       "5       Can I get a mortgage with a 580 credit score?  unacceptable      0   \n",
       "6            How long does the mortgage process take?    acceptable      0   \n",
       "7                        What credit score do I need?    acceptable      0   \n",
       "8      Do I need mortgage insurance with an FHA loan?  unacceptable      0   \n",
       "9       Is an FHA or conventional loan better for me?  unacceptable      0   \n",
       "10                        How much are closing costs?  unacceptable      0   \n",
       "11            What rate can I get on a 30-year fixed?  unacceptable      0   \n",
       "12       Will I get approved for a conventional loan?  unacceptable      0   \n",
       "13       What are my options if my rate lock expires?    acceptable      1   \n",
       "14                    What's the VA loan funding fee?    acceptable      1   \n",
       "15                      What is a Closing Disclosure?    acceptable      1   \n",
       "16          Can I use gift money for my down payment?    acceptable      1   \n",
       "17  What documents do I need to apply for a mortgage?    acceptable      1   \n",
       "18                               How do I remove PMI?    acceptable      1   \n",
       "19   What's the minimum down payment for an FHA loan?    acceptable      1   \n",
       "20                     Can I negotiate closing costs?    acceptable      0   \n",
       "21                        How much home can I afford?    acceptable      0   \n",
       "22   What happens to my loan if the servicer changes?    acceptable      0   \n",
       "23           Should I pay points to buy down my rate?    acceptable      0   \n",
       "24  What's the difference between pre-qualificatio...    acceptable      0   \n",
       "25      Can I get a mortgage with a 580 credit score?  unacceptable      0   \n",
       "26           How long does the mortgage process take?    acceptable      0   \n",
       "27                       What credit score do I need?    acceptable      0   \n",
       "28     Do I need mortgage insurance with an FHA loan?  unacceptable      0   \n",
       "29      Is an FHA or conventional loan better for me?  unacceptable      0   \n",
       "30                        How much are closing costs?  unacceptable      0   \n",
       "31            What rate can I get on a 30-year fixed?  unacceptable      0   \n",
       "32       Will I get approved for a conventional loan?  unacceptable      0   \n",
       "33       What are my options if my rate lock expires?    acceptable      1   \n",
       "34                    What's the VA loan funding fee?    acceptable      1   \n",
       "35                      What is a Closing Disclosure?    acceptable      1   \n",
       "36          Can I use gift money for my down payment?    acceptable      1   \n",
       "37  What documents do I need to apply for a mortgage?    acceptable      1   \n",
       "38                               How do I remove PMI?    acceptable      1   \n",
       "39   What's the minimum down payment for an FHA loan?    acceptable      1   \n",
       "\n",
       "   verdict  \n",
       "0     FAIL  \n",
       "1     FAIL  \n",
       "2     FAIL  \n",
       "3     FAIL  \n",
       "4     FAIL  \n",
       "5     FAIL  \n",
       "6     FAIL  \n",
       "7     FAIL  \n",
       "8     FAIL  \n",
       "9     FAIL  \n",
       "10    FAIL  \n",
       "11    FAIL  \n",
       "12    FAIL  \n",
       "13    PASS  \n",
       "14    PASS  \n",
       "15    PASS  \n",
       "16    PASS  \n",
       "17    PASS  \n",
       "18    PASS  \n",
       "19    PASS  \n",
       "20    FAIL  \n",
       "21    FAIL  \n",
       "22    FAIL  \n",
       "23    FAIL  \n",
       "24    FAIL  \n",
       "25    FAIL  \n",
       "26    FAIL  \n",
       "27    FAIL  \n",
       "28    FAIL  \n",
       "29    FAIL  \n",
       "30    FAIL  \n",
       "31    FAIL  \n",
       "32    FAIL  \n",
       "33    PASS  \n",
       "34    PASS  \n",
       "35    PASS  \n",
       "36    PASS  \n",
       "37    PASS  \n",
       "38    PASS  \n",
       "39    PASS  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull evaluation trace outputs into DataFrames to verify metric scores were recorded\n",
    "\n",
    "# Generic metrics\n",
    "generic_runs = [r for r in runs if r.name == \"deepeval_generic_metrics\"]\n",
    "generic_rows = []\n",
    "for r in generic_runs:\n",
    "    row = {\"label\": r.inputs.get(\"label\", \"\"), \"input\": r.inputs.get(\"input\", \"\")[:80]}\n",
    "    if r.outputs:\n",
    "        row.update(r.outputs)\n",
    "    generic_rows.append(row)\n",
    "\n",
    "df_generic_traces = pd.DataFrame(generic_rows)\n",
    "print(f\"--- deepeval_generic_metrics ({len(generic_rows)} traces) ---\")\n",
    "display(df_generic_traces)\n",
    "\n",
    "# Golden dataset\n",
    "golden_runs = [r for r in runs if r.name == \"deepeval_golden_dataset\"]\n",
    "golden_rows = []\n",
    "for r in golden_runs:\n",
    "    row = {\"input\": r.inputs.get(\"input\", \"\")[:80], \"label\": r.metadata.get(\"label\", \"\")}\n",
    "    if r.outputs:\n",
    "        row.update(r.outputs)\n",
    "    golden_rows.append(row)\n",
    "\n",
    "df_golden_traces = pd.DataFrame(golden_rows)\n",
    "print(f\"\\n--- deepeval_golden_dataset ({len(golden_rows)} traces) ---\")\n",
    "display(df_golden_traces)\n",
    "\n",
    "# IRR evaluations\n",
    "irr_runs = [r for r in runs if r.name == \"deepeval_irr_evaluation\"]\n",
    "irr_rows = []\n",
    "for r in irr_runs:\n",
    "    row = {\n",
    "        \"input\": r.inputs.get(\"input\", \"\")[:60],\n",
    "        \"human_label\": r.inputs.get(\"human_label\", \"\"),\n",
    "    }\n",
    "    if r.outputs:\n",
    "        row.update({k: v for k, v in r.outputs.items() if k != \"human_label\"})\n",
    "    irr_rows.append(row)\n",
    "\n",
    "df_irr_traces = pd.DataFrame(irr_rows)\n",
    "print(f\"\\n--- deepeval_irr_evaluation ({len(irr_rows)} traces) ---\")\n",
    "df_irr_traces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Eval Workshop",
   "language": "python",
   "name": "ai-eval-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "002bbc443c444962ac7c334c1996c94f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0058d904986b4b6c98fb30a7b915052d": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_bffbb641a4994571b5afa1cf5b2aa15a",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "00b9a6382d8245af846493920b5a4902": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_6604cc5cda5b46b9bfb052838445006d",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "03b3c95dcad54ba7b9a864e0ddfbaf6c": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ebef4aad0e6a4a2c8a4a460545e6ba7f",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=T…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=T…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "05650bc5cfe94f17934b2cec47868ba6": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_b9b738e160ea4b2d872687dc1d3125a8",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=True,…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=True,…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "05bc72b5324741149e0e5770426cba8c": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_8cad0219bc06471a90897281e087efea",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "05d2ba735e7a44a89bb22e79a00fcc0a": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_c315e4fee60443f1bdda7da3ca2505c9",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "08373b25b15e4f6591c212097ff4ee06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b96d5ec4ac24c7db6b27f99fa2c965a": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_b2f461db057641dc955afed6f2ba53f0",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "0efdd76041ef416bbd816a44009222bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1395b8ce5c844aa287bfd1c3efa3a9c5": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_5c1e538dc42b40db92670fb24dbfed61",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "15000bba628642fbb96926f332062966": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_2ac03c2c160f45b99b4664e53506431d",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), stri…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), stri…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "163a8197f8b24e379c7cbd2bab6edc05": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_d4ab01d37ad64a9aa6a42ae5bea3dc48",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=True,…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=True,…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "16d3265a36554f289679865fee415257": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19c1127a5f3946449d7ff30f6bac7114": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ab88efaec0c54a189f00203f7a0391f3",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "1bc25785d95643a4a0dfd209c052f576": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_3dfe3217cb07494abb60489dd6e7befe",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "1cd66790497b4f7aa58ec36598c89a83": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_5c8149ff0e78449da95849321ef34b1c",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "1cec1c4882574580b9366a18c7dbd433": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_665310ed5789494db20fb8ac498e7906",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), stri…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), stri…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "1eaa7e79dcb44ef794bb419efbcb5f15": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_e117dcc260c64fc6bab7a210901d0a2c",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "1fc52abed4e14cdebdd2fdad7b219e36": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20f1ec4bd52e43188e744fb35235e1dc": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_bedba19744de493cb74df1f4ad0e1f76",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "22033a61e3294648b093ec0290017d2d": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_5e3ee0aaa58147aa9cd3093bd250aae2",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12936' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12937' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11b927b40&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11b927b40&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12937' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12939' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12940' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba14640&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12940' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12942' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12943' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba16840&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12943' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12945' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12946' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba14d40&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12946' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12948' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12949' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba17740&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12949' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12951' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12952' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba16140&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12952' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12954' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12955' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba17340&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12955' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12957' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12958' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba17140&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12958' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12960' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12961' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba16940&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12961' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12963' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12964' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba14140&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12964' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12966' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12967' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba16340&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12967' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12969' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12970' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba16040&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12970' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12972' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12973' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba17b40&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12973' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12975' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12976' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba14e40&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12976' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12978' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12979' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba14f40&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12979' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12981' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12982' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11ba17a40&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12982' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12984' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12985' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11b9e8440&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12985' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12987' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12988' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11b9e8940&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12988' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12990' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12991' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11b9ebe40&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12991' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12993' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12994' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11b9e8540&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12994' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12996' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12997' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nException ignored in: &lt;coroutine object Kernel.shell_main at 0x11b9e9440&gt;\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;lambda&gt;\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12997' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\n✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "Task was destroyed but it is pending!\ntask: <Task pending name='Task-12936' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12937' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11b927b40>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nException ignored in: <coroutine object Kernel.shell_main at 0x11b927b40>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12937' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12939' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12940' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba14640>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12940' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12942' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12943' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba16840>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12943' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12945' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12946' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba14d40>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12946' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12948' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12949' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba17740>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12949' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12951' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12952' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba16140>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12952' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12954' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12955' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba17340>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12955' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12957' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12958' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba17140>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12958' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12960' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12961' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba16940>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12961' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12963' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12964' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba14140>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12964' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12966' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12967' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba16340>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12967' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12969' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12970' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba16040>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12970' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12972' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12973' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba17b40>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12973' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12975' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12976' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba14e40>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12976' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12978' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12979' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba14f40>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12979' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12981' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12982' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11ba17a40>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12982' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12984' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12985' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11b9e8440>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12985' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12987' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12988' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11b9e8940>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12988' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12990' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12991' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11b9ebe40>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12991' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12993' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12994' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11b9e8540>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12994' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12996' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12997' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nException ignored in: <coroutine object Kernel.shell_main at 0x11b9e9440>\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <lambda>\nKeyError: '__import__'\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12997' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\n✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "227488e568f643048a77eeaa1bffe690": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_a2a5a20c4b0542eb977c13695c0e18da",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "23a084ac09364887a6a932d4b0a943be": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_753c404b7ece43159bf4443d76e7c064",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "256f33ed2bb047849405b96cdf1bb820": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2777ed57450948c29bdc615169fefb4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "290edee4fa2a424c8a5f75f3ef359382": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_7409f7b644a44e2ba20b7f52334016c6",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "29af3f7007ac419d9333f70aec244a64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a7dbde68ac4410b81d9a88c959de09d": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_3fac57864fe847b7a913b50c4f121851",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "2ac03c2c160f45b99b4664e53506431d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b25263440f34e6cb23b06302f34ddcb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e1ab316e98c457cad6b6e649f90b015": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_e2fe54dc4c6a4e789b6f370295caa953",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "2e44048e558a40638d1a66f4a69fdcc0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f1f616eb2c64aafbbf2c598ef74514f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f5afbaec11b49d191835d4011cf6a06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "31dbcf8f40514d4bb8d5a6430e7b1247": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_87a1bc43aff6430e8de7efa8919bf2ff",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "32d7c10af7654e32a52a4a9485c85aa5": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ee6747ee359a41babfd54ffb5c532330",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=T…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=T…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "33650c616ffa4518be425e9f0916dc5c": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_9aaf9a43339f49c398c7d0addd6a7b37",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "36b1dd093ae34fc3aca9afaa9b46b8b0": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_bf3a6c679d6e45e7aaf480d0e9694ecd",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task was destroyed but it is pending!\ntask: &lt;Task pending name='Task-2815' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-2816' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\n</pre>\n",
          "text/plain": "Task was destroyed but it is pending!\ntask: <Task pending name='Task-2815' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-2816' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\n"
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task was destroyed but it is pending!\ntask: &lt;Task pending name='Task-2816' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\n</pre>\n",
          "text/plain": "Task was destroyed but it is pending!\ntask: <Task pending name='Task-2816' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\n"
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=True,…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=True,…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "3c4d23566e4d402f88c87f9e91ad2258": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_7a60891a66cc477f9139c5f72ddf1096",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), stri…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), stri…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "3d8c20468ce544e0ba0ad69b7b8166ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3df9c0e948894cbfb1ac9a670164ede9": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_256f33ed2bb047849405b96cdf1bb820",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "3dfe3217cb07494abb60489dd6e7befe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e74daf97e994387b733437b4e0ffffb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e98751c52da40d19eef9c1044fd79a6": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_b11b44ecaa654ee38c7aa6d15f89575a",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "3ea95763437642d58fe083c96faa1089": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_f9f893023d414ee4b8c092d3abeae151",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "3fac57864fe847b7a913b50c4f121851": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4089b2b27aa9405698272e93a1f8c1a9": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_8992d7797c5f4a999cd39abb6bacd3f1",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "44b975d13eef4f579d4f36082050931f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46647d431b4d42c7a549461ef3c0815c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48f01077acd04754bab5094bf72c526c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b545b10c8a842a2819efca869855d8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c534872efb746aa85232c870fdbf793": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d04d367082f4ed7b71977f01ff7dfa2": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_d50d8cb8b0fb44a6ad7c125c39adb589",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "4dd2fe87445a41519602f45f44ef0b25": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ccedeba8c1e74d98af92f33f825d0d4e",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "51d9e78c6c424b299ac6c8590441f8e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51ed9a19efdb4f3b83aef29f38ef7b4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "547dd451512e489789e7acb4a0b27ac9": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_d8a9d6dd6f274a209356cbb87f96c25d",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "54f40ef01459478d86999f766f9a1b48": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_b50be5d7cf7b4ad09464f0cf08fa6572",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "560593f5a5384669af1e5db89c0d7f08": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_5915b1f00ad64288aed3a6457e542a5b",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=T…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=T…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "5915b1f00ad64288aed3a6457e542a5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "596c621c91b9428a93e55b3eb1a746d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b8eb86d2d64479dba641e45136e6cdc": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_e1b15716ce7641c2bde4b23ac5f40eae",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), stri…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), stri…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "5c1e538dc42b40db92670fb24dbfed61": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c8149ff0e78449da95849321ef34b1c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e3ee0aaa58147aa9cd3093bd250aae2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ef75b63cf58480f82b7ee2ec811fd54": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_002bbc443c444962ac7c334c1996c94f",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "602075093b424efcb8ce6149a3de6556": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_29af3f7007ac419d9333f70aec244a64",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task was destroyed but it is pending!\ntask: &lt;Task pending name='Task-11930' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-11931' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:60&gt; wait_for=&lt;Task pending name='Task-11932' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-11929' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:60&gt; wait_for=&lt;Task pending name='Task-11930' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-11932' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12378' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12379' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12379' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12381' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12382' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12382' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12384' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12385' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12385' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12387' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12388' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12388' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12390' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12391' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12391' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12393' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12394' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12394' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12396' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12397' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12397' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12399' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12400' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12400' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12402' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12403' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12403' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12405' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12406' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12406' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12408' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12409' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12409' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12411' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12412' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12412' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12414' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12415' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12415' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12417' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12418' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12418' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12420' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12421' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12421' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12423' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12424' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12424' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12426' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12427' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12427' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12429' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12430' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12430' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12432' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12433' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12433' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12435' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-12436' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-12436' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\n✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "Task was destroyed but it is pending!\ntask: <Task pending name='Task-11930' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-11931' coro=<_async_in_context.<locals>.run_in_context() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:60> wait_for=<Task pending name='Task-11932' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-11929' coro=<_async_in_context.<locals>.run_in_context() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:60> wait_for=<Task pending name='Task-11930' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-11932' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12378' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12379' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12379' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12381' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12382' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12382' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12384' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12385' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12385' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12387' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12388' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12388' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12390' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12391' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12391' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12393' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12394' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12394' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12396' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12397' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12397' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12399' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12400' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12400' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12402' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12403' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12403' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12405' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12406' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12406' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12408' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12409' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12409' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12411' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12412' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12412' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12414' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12415' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12415' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12417' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12418' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12418' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12420' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12421' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12421' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12423' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12424' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12424' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12426' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12427' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12427' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12429' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12430' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12430' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12432' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12433' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12433' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12435' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-12436' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-12436' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\n✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "6604cc5cda5b46b9bfb052838445006d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66530f52bdaa4e7d90b04a2a007a5c95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "665310ed5789494db20fb8ac498e7906": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "676638c9cd464114b4c997be82226945": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d74c5eccf73424db3b57edebed31429": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ec05791e558e412fb0eb88f6b5075296",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=T…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=T…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "70ee61e5db7e4aab9c97e1101321c747": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70f6e9cae11d4f98a0b1148acf7c4248": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "722ae7baebfe44bababa32a1b3923b61": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_d54c52894964486b878f94bda15d6be4",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "7409f7b644a44e2ba20b7f52334016c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74ca24e00ad8460a90cbeb2fd693a741": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "753c404b7ece43159bf4443d76e7c064": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77133142c1ab41139478149e533cb912": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77a62a39d8f2414d94b449815a400db3": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_c1d25dd24c5e49209bbb83ed6f701bc0",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "77da470c3ca54c2e81cb90b597088d3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "789cff2d0ce44ea3b0fdd6ebbadb9e74": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_2777ed57450948c29bdc615169fefb4a",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=T…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=T…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "79522d47a0cf430fb2a74ad00aaef39c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a60891a66cc477f9139c5f72ddf1096": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f0107e774564e6c8a45dc55638a56e2": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_90ccad571a3446a3b68056015b315c93",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "7f262633541243f0bf2ebd34ba4b838d": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ea85cb31052d4ee7b808076a01215a5c",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "87a1bc43aff6430e8de7efa8919bf2ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8992d7797c5f4a999cd39abb6bacd3f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "899f7bb5ccd44bd68c2c9dd16cd11739": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b59894a25d24d14ad9f6c9258b36297": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_dce08e20510f4fd6a59247ec9927bbbd",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "8c410928a9b94391bf03ca6bcbccb178": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_899f7bb5ccd44bd68c2c9dd16cd11739",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "8cad0219bc06471a90897281e087efea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90267fe6b1844d23a3b8bc9ff4f8f4b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90a14cec732640bb9c375a0bd78db6c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90af8e1ff2e64246a659dd67f9900da7": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_51d9e78c6c424b299ac6c8590441f8e6",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=True,…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=True,…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "90ccad571a3446a3b68056015b315c93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92f98a6ba11f44fcb30ffb5aab1b0673": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "95c222b9c6c740638b56270578e0f1b5": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_90a14cec732640bb9c375a0bd78db6c8",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "9a376ff3f80c4b10b536d040d104199b": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_a55a5b6a2a334085ac4a23ec3aadc118",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "9aaf9a43339f49c398c7d0addd6a7b37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b9dd737735d41969fd0e96a0661f6ba": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_51ed9a19efdb4f3b83aef29f38ef7b4f",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "9ba782c51e4345d98b235f1ad94273bd": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_44b975d13eef4f579d4f36082050931f",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=T…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=T…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "9bb1cb40a6ee4b349ffe1734989c6e0a": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_1fc52abed4e14cdebdd2fdad7b219e36",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "9c30229bd9994ede9e5156eff841af6a": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_676638c9cd464114b4c997be82226945",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "9de2bda1bd914f6fb0f03f457c02b3a4": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_b22158da899c4ead8c736e51d8fcd31c",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), stri…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), stri…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "9ffece859e33482eb4f09f2b8ba607bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a23f67ba26ce434d8c343297384eb37b": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_9ffece859e33482eb4f09f2b8ba607bb",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=True,…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=True,…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "a26184f1c0a7420fb3e1e017c551d106": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2a5a20c4b0542eb977c13695c0e18da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a3936f8c7c7047c8b40998e20c93edae": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_cf386411795c401c94eba86c955ee6e5",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=True,…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=True,…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "a55a5b6a2a334085ac4a23ec3aadc118": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8dd4b10abb04b2e81321bddfa093ba9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab3f86f4972d4c20b8434001328a78b5": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_f9981abdf5344a25989598d0c41c4e91",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), stri…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), stri…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "ab88efaec0c54a189f00203f7a0391f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac3a70ae4e2b43c995501f4046445e37": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_3e74daf97e994387b733437b4e0ffffb",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "ad02efdcd7cd4954b28a5edc337871db": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_77da470c3ca54c2e81cb90b597088d3a",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "b11b44ecaa654ee38c7aa6d15f89575a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b22158da899c4ead8c736e51d8fcd31c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2f461db057641dc955afed6f2ba53f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b50be5d7cf7b4ad09464f0cf08fa6572": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b53492523c4d422aaab0316025ec0f29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b69c948d40bc435e8a49720f016ab7f3": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_2f5afbaec11b49d191835d4011cf6a06",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "b9b738e160ea4b2d872687dc1d3125a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9c44ed371cb44cb8d5856c5deb0b6e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be28eb158c154c4587424b63f71aede9": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ece0a625869644d692d08ce9ed83a11f",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "be4fe83be78d458598f3ff6a36c34d5e": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_70ee61e5db7e4aab9c97e1101321c747",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "bedba19744de493cb74df1f4ad0e1f76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf3a6c679d6e45e7aaf480d0e9694ecd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bffbb641a4994571b5afa1cf5b2aa15a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c128784136ea482290e33ce3f85d55ed": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_16d3265a36554f289679865fee415257",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "c1738b27c16a4f1788a634ff6826c937": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_b53492523c4d422aaab0316025ec0f29",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "c1d25dd24c5e49209bbb83ed6f701bc0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c315e4fee60443f1bdda7da3ca2505c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3310965ca614571ac995654a74f1a8b": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_4b545b10c8a842a2819efca869855d8a",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=True,…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=True,…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "c4e2e48112f04d24bef32b08961bfd73": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_df95313175474c3aa3b8f2d823d400f2",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "c83874808ae74c498bb6e658361d9e22": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_48f01077acd04754bab5094bf72c526c",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), stri…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), stri…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "caa0ebc51a5f4acbae0a40d65837d71a": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_90267fe6b1844d23a3b8bc9ff4f8f4b1",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=T…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=T…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "cc78d4ba924748519bb5da31748e0dcf": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_77133142c1ab41139478149e533cb912",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3401' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3402' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3402' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3404' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3405' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3405' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3407' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3408' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3408' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3410' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3411' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3411' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3413' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3414' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3414' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3416' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3417' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3417' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3419' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3420' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3420' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3422' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3423' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3423' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3425' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3426' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3426' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3428' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3429' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3429' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3431' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3432' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3432' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3434' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3435' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3435' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3437' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3438' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3438' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3440' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3441' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3441' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3443' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3444' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3444' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3446' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3447' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3447' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3449' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3450' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3450' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3452' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3453' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3453' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3455' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3456' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3456' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3458' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3459' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3459' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\n✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), stri…</span>\n</pre>\n",
          "text/plain": "Task was destroyed but it is pending!\ntask: <Task pending name='Task-3401' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3402' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3402' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3404' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3405' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3405' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3407' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3408' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3408' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3410' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3411' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3411' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3413' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3414' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3414' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3416' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3417' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3417' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3419' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3420' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3420' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3422' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3423' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3423' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3425' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3426' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3426' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3428' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3429' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3429' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3431' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3432' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3432' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3434' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3435' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3435' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3437' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3438' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3438' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3440' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3441' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3441' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3443' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3444' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3444' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3446' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3447' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3447' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3449' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3450' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3450' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3452' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3453' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3453' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3455' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3456' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3456' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3458' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3459' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-3459' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\n✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), stri…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "ccedeba8c1e74d98af92f33f825d0d4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cea3e69691c54ee6aeffacaa361d8764": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_596c621c91b9428a93e55b3eb1a746d2",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=True,…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=True,…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "cf386411795c401c94eba86c955ee6e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfa70b5cb9f24345943f668411d97ece": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_0efdd76041ef416bbd816a44009222bf",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "d4ab01d37ad64a9aa6a42ae5bea3dc48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d50d8cb8b0fb44a6ad7c125c39adb589": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d54c52894964486b878f94bda15d6be4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d641e431eb644fdab7f10b8fdfc97667": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_b9c44ed371cb44cb8d5856c5deb0b6e7",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "d8a9d6dd6f274a209356cbb87f96c25d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dce08e20510f4fd6a59247ec9927bbbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dce419137aa342a2b6da0be474287262": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_de1da65e07fe4544a1929a7939d68a85",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "dd540f43907e47be8dec2db3904402ad": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_66530f52bdaa4e7d90b04a2a007a5c95",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=True,…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=True,…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "ddb5c5d32fc64a20bc9d65467ab674ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de1da65e07fe4544a1929a7939d68a85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de6118ad14e24b588b7b0c17cda2fb7c": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_2b25263440f34e6cb23b06302f34ddcb",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "de87d65c8d844abbb7d660d3dcce6ef2": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ddb5c5d32fc64a20bc9d65467ab674ed",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "defece5b78c841a6b7cb89c6900cf3e5": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_74ca24e00ad8460a90cbeb2fd693a741",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=T…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=T…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "df273fa5a8ab46688cb8fadcaa1bc237": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_79522d47a0cf430fb2a74ad00aaef39c",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "df95313175474c3aa3b8f2d823d400f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e117dcc260c64fc6bab7a210901d0a2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1b15716ce7641c2bde4b23ac5f40eae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2fe54dc4c6a4e789b6f370295caa953": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7307e9a08b149c08e66b67841f1e27d": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_2f1f616eb2c64aafbbf2c598ef74514f",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "e86b5dc06b184275814868a3699d1f7c": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_08373b25b15e4f6591c212097ff4ee06",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "ea85cb31052d4ee7b808076a01215a5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb65b357d061460999d87db2dbeb0ea4": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_2e44048e558a40638d1a66f4a69fdcc0",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "ebb3becae5444f0bad404d3a3738ecf9": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_92f98a6ba11f44fcb30ffb5aab1b0673",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "ebef4aad0e6a4a2c8a4a460545e6ba7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec05791e558e412fb0eb88f6b5075296": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec7fc2c3a7af4931ba17afbfc1691273": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ece0a625869644d692d08ce9ed83a11f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee6747ee359a41babfd54ffb5c532330": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f21952ee81fe4a6ba6edd3fec117fc69": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ec7fc2c3a7af4931ba17afbfc1691273",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3207' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\n</pre>\n",
          "text/plain": "Task was destroyed but it is pending!\ntask: <Task pending name='Task-3207' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\n"
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3209' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-3210' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\n</pre>\n",
          "text/plain": "Task was destroyed but it is pending!\ntask: <Task pending name='Task-3209' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-3210' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\n"
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task was destroyed but it is pending!\ntask: &lt;Task pending name='Task-3210' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\n</pre>\n",
          "text/plain": "Task was destroyed but it is pending!\ntask: <Task pending name='Task-3210' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\n"
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=T…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=T…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "f9981abdf5344a25989598d0c41c4e91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9f893023d414ee4b8c092d3abeae151": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa927f02164345b5bdbb798b3cd13c8a": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_46647d431b4d42c7a549461ef3c0815c",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), stri…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), stri…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "fb7e7c1132e947da84514620f46e31fb": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_70f6e9cae11d4f98a0b1148acf7c4248",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "fc48fe355e6f469daa53a9f9abaddb06": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_a26184f1c0a7420fb3e1e017c551d106",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "fdb9cdaf3d5f41b68c8bdbe52f4999d5": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_3d8c20468ce544e0ba0ad69b7b8166ac",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13529' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13530' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13530' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13532' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13533' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13533' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13535' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13536' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13536' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13538' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13539' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13539' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13541' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13542' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13542' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13544' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13545' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13545' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13547' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13548' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13548' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13550' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13551' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13551' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13553' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13554' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13554' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13556' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13557' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13557' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13559' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13560' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13560' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13562' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13563' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13563' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13565' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13566' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13566' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13568' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13569' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13569' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13571' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13572' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13572' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13574' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13575' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13575' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13577' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13578' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13578' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13580' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13581' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13581' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13583' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13584' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13584' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13586' coro=&lt;_async_in_context.&lt;locals&gt;.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57&gt; wait_for=&lt;Task pending name='Task-13587' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt; cb=[ZMQStream._run_callback.&lt;locals&gt;._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]&gt;\nTask was destroyed but it is pending!\ntask: &lt;Task pending name='Task-13587' coro=&lt;Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597&gt; cb=[Task.__wakeup()]&gt;\n✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Actionability [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), str…</span>\n</pre>\n",
          "text/plain": "Task was destroyed but it is pending!\ntask: <Task pending name='Task-13529' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13530' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13530' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13532' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13533' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13533' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13535' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13536' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13536' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13538' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13539' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13539' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13541' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13542' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13542' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13544' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13545' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13545' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13547' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13548' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13548' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13550' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13551' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13551' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13553' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13554' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13554' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13556' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13557' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13557' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13559' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13560' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13560' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13562' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13563' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13563' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13565' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13566' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13566' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13568' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13569' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13569' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13571' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13572' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13572' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13574' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13575' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13575' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13577' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13578' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13578' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13580' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13581' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13581' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13583' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13584' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13584' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13586' coro=<_async_in_context.<locals>.run_in_context() done, defined at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/utils.py:57> wait_for=<Task pending name='Task-13587' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/zm\nq/eventloop/zmqstream.py:563]>\nTask was destroyed but it is pending!\ntask: <Task pending name='Task-13587' coro=<Kernel.shell_main() running at \n/Users/nathansuberi/Documents/GitHub/ai-evals-in-context/interactive-notebook/.venv/lib/python3.12/site-packages/ip\nykernel/kernelbase.py:597> cb=[Task.__wakeup()]>\n✨ You're running DeepEval's latest \u001b[38;2;106;0;255mActionability [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), str…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "fdc0d17098224820a47efc9d93113c5b": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_a8dd4b10abb04b2e81321bddfa093ba9",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Regulatory Compliance [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthrop…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRegulatory Compliance [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthrop…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "fe3f7efa08c649e2a97ee0faebd34ca9": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_4c534872efb746aa85232c870fdbf793",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using claude-sonnet-4-20250514 (Anthropic), strict=…</span>\n</pre>\n",
          "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[38;2;55;65;81m(using claude-sonnet-4-20250514 (Anthropic), strict=…\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
